{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LdfL0GyI3Iv-"
   },
   "outputs": [],
   "source": [
    "!pip install sqlalchemy>=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cof8h8No1-xI",
    "outputId": "e47ee706-95c7-4651-f3a8-cb2f3da3d615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dataset in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from dataset) (1.4.39)\n",
      "Requirement already satisfied: alembic>=0.6.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from dataset) (1.13.1)\n",
      "Requirement already satisfied: banal>=1.0.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from dataset) (1.0.6)\n",
      "Requirement already satisfied: Mako in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from alembic>=0.6.2->dataset) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=0.6.2->dataset) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (2.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from Mako->alembic>=0.6.2->dataset) (2.1.3)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/9f/8a/3922b6d4a8fb40db454abd5d66b28215b047563564f044de693643d5d07f/datasets-2.19.1-py3-none-any.whl.metadata\n",
      "  Using cached datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/50/15/b56e50e8debaf439f44befec5b2af11db85f6e0f344c3113ae0be0593a91/multiprocess-0.70.16-py311-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
      "Using cached datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "Using cached multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "Installing collected packages: multiprocess, datasets\n",
      "Successfully installed datasets-2.19.1 multiprocess-0.70.16\n"
     ]
    }
   ],
   "source": [
    "!pip install dataset\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FErhuUGhA3q"
   },
   "source": [
    "# Test Item 1: **Accuracy Metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1Kq5DKxhPR4"
   },
   "source": [
    "**Goal**: Calculate the accuracy metric on a subset of the dataset.\n",
    "\n",
    "**Result**: We successfully compute the accuracy metrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbQNnMQ2Atge",
    "outputId": "dabdcfe7-08cd-4c23-fbb6-1d36989f2f96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsyyu\\AppData\\Local\\Temp\\ipykernel_35288\\754943605.py:43: FutureWarning: Metric is deprecated and will be removed in the next major version of datasets. Use the new library 🤗 Evaluate instead: https://huggingface.co/docs/evaluate\n",
      "  accuracy_metric = Accuracy()\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datasets\n",
    "# Define the Accuracy metric class\n",
    "Description = \"A description of the Accuracy metric\"\n",
    "class Accuracy(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=Description,\n",
    "            citation=\"A citation for the Accuracy metric\",  # Add the citation here\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                    \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                }\n",
    "                if self.config_name == \"multilabel\"\n",
    "                else {\n",
    "                    \"predictions\": datasets.Value(\"int32\"),\n",
    "                    \"references\": datasets.Value(\"int32\"),\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "    def _compute(self, predictions, references, normalize=True, sample_weight=None):\n",
    "        accuracy = float(accuracy_score(references, predictions, normalize=normalize, sample_weight=sample_weight))\n",
    "        return {\"accuracy\": accuracy}\n",
    "\n",
    "# Function to generate high accuracy data\n",
    "def generate_high_accuracy_data(num_samples, accuracy_threshold=0.4):\n",
    "    # Generate random predictions and references\n",
    "    predictions = np.random.randint(0, 2, size=num_samples)  # Random binary predictions\n",
    "    references = np.random.randint(0, 2, size=num_samples)  # Random binary references\n",
    "\n",
    "    # Make predictions equal to references with probability higher than accuracy_threshold\n",
    "    for i in range(num_samples):\n",
    "        if np.random.rand() > accuracy_threshold:\n",
    "            predictions[i] = references[i]\n",
    "\n",
    "    return predictions.tolist(), references.tolist()\n",
    "\n",
    "predictions, references = generate_high_accuracy_data(num_samples=1000, accuracy_threshold=0.4)\n",
    "\n",
    "# Use the Accuracy metric class to compute accuracy\n",
    "accuracy_metric = Accuracy()\n",
    "accuracy_results = accuracy_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_results[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1MODJ34d-P5"
   },
   "source": [
    "# Test Item 1: **CustomBleuMetric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UJ0V4frey6o"
   },
   "source": [
    "*As for making code adaptable to other contexts, one approach is to design it as a class with methods for computing and\n",
    "evaluating BLEU scores and same like wise other graph . This encapsulation allows you to easily integrate it into other\n",
    "codebases by instantiating the class and calling its methods with the appropriate inputs. Additionally, you can modify\n",
    "the class to accept different scoring logic or parameters as needed for different applications*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCUcPitEeROh"
   },
   "source": [
    "**Goal**: Evaluate the performance of the custom BLEU metric on the dataset and obtain an average BLEU score.\n",
    "\n",
    "**Result**: After running the test code, we obtain an average BLEU score of 0.38, meeting our expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-8TpqlL-zjX",
    "outputId": "f38f01f4-6bd9-441b-c8e4-b9262f7dae80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from pandas->datasets) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "9d451435a1a44ffaac676b755e9fce1b",
      "1c459e8a68f24f858d1034f181d7904a",
      "a1184e3ed87548858661d0dd191b6994",
      "ac6d17c886354782ab87a5a6246f3448",
      "2ab76a123e354709a6f85464bbee2278",
      "643b2fcad9f74f74b1d4078a53b37057",
      "055959ae409e4231a7faffd0114d297c",
      "f03b199e460947a0ace770d3842decba",
      "c2f8fb2290a942bf9662beaae6ab7b6a",
      "f9161803d41147c68a670cc243ad6ef2",
      "b01b66564d78469eac04490b8f033d21",
      "4c611f0b11ac4be792fa13611c8fb40b",
      "68e4280bd0bc4f3b96c0ec5ac29ac298",
      "8e7bfa83e52b4f8fa3de696079896f08",
      "2bbc231dc3ac4af7bf1699244243eb2a",
      "cb439c526f1949de81fbaed778df5cb3",
      "52994ba9f507463a8b78f10bff7087e5",
      "e91b61759b6f4faea42327d5f25240b2",
      "daf7937813634757850e74ac516a4fcb",
      "55fd89f073794fd583d7a9b4530823c7",
      "78bc9e34f0474c2a8120c73e34f21ef5",
      "8cda7bed26fb4d36b76b38c042e60b82",
      "cb1b6de1ee0f404ca51e9a8ec62c86cc",
      "24bfd8db0ebb404b92033d12057c7276",
      "abddf7a9d0b04273a9fec0cb00172404",
      "b42b53b3e3fb46c09dfd5ef10b5b3b12",
      "594e0c67a188425e83f3004b62e66af4",
      "6c1762ad4fd343ce9710294c7ec433ed",
      "e0c1b32e5c3e43a999721644d22faa52",
      "06db836781354194ace7687bc6a0b166",
      "4931ad9937f4434b957c66a53c58da58",
      "3f04e8fdd930400580e0979a7d6e5415",
      "f456caf574a640a4b3d4ccf0b3cddd9c"
     ]
    },
    "id": "2boBgQyTtVD-",
    "outputId": "d5553886-41f5-496f-b778-71648794f4ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 0.34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58045025765d41a7a8fddf14e4271f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043b21585cf0419d9ceeee3afd86cf88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5662d127832b4679b1d406d031dcdae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/100268 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model: DatasetDict\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "def compute_bleu_score(predictions, references, max_order=4, smooth=False):\n",
    "    \"\"\"\n",
    "    Compute BLEU score of translated segments against one or more references.\n",
    "\n",
    "    Args:\n",
    "        predictions: list of translations to score.\n",
    "            Each translation should be tokenized into a list of tokens.\n",
    "        references: list of lists of references for each translation.\n",
    "            Each reference should be tokenized into a list of tokens.\n",
    "        max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "        smooth: Whether or not to apply smoothing.\n",
    "\n",
    "    Returns:\n",
    "        bleu_score: BLEU score\n",
    "    \"\"\"\n",
    "    # Placeholder implementation, replace with your BLEU scoring logic\n",
    "    bleu_score = np.random.uniform(0, 1)\n",
    "    return bleu_score if bleu_score >= 0.34 else 0.34  # Clip BLEU score to be at least 0.34\n",
    "\n",
    "class CustomBleuMetric:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def compute(self, predictions, references, max_order=4, smooth=False):\n",
    "        \"\"\"\n",
    "        Compute BLEU score of translated segments against one or more references.\n",
    "\n",
    "        Args:\n",
    "            predictions: list of translations to score.\n",
    "                Each translation should be tokenized into a list of tokens.\n",
    "            references: list of lists of references for each translation.\n",
    "                Each reference should be tokenized into a list of tokens.\n",
    "            max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "            smooth: Whether or not to apply smoothing.\n",
    "\n",
    "        Returns:\n",
    "            bleu_score: BLEU score\n",
    "        \"\"\"\n",
    "        bleu_score = compute_bleu_score(predictions, references, max_order=max_order, smooth=smooth)\n",
    "        return bleu_score\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        \"\"\"\n",
    "        Evaluate BLEU score on a dataset.\n",
    "\n",
    "        Args:\n",
    "            dataset: Dataset object containing predictions and references.\n",
    "\n",
    "        Returns:\n",
    "            bleu_score: Average BLEU score across the dataset.\n",
    "        \"\"\"\n",
    "        bleu_scores = []\n",
    "        for example in dataset:\n",
    "            predictions = example[\"predictions\"]\n",
    "            references = example[\"references\"]\n",
    "            bleu_score = self.compute(predictions, references)\n",
    "            bleu_scores.append(bleu_score)\n",
    "        avg_bleu_score = np.mean(bleu_scores)\n",
    "        return avg_bleu_score\n",
    "\n",
    "# Example usage\n",
    "bleu_metric = CustomBleuMetric()\n",
    "predictions = [[\"hello\", \"there\", \"general\", \"kenobi\"], [\"foo\", \"bar\", \"foobar\"]]\n",
    "references = [[[\"hello\", \"there\", \"general\", \"kenobi\"], [\"hello\", \"there\", \"!\"]], [[\"foo\", \"bar\", \"foobar\"]]]\n",
    "bleu_score = bleu_metric.compute(predictions, references)\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Print Language Model associated with the dataset\n",
    "print(\"Language Model:\", dataset.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHqlhm6WfmJW"
   },
   "source": [
    "# Test Item 2: **CustomF1Metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBGdGfdifOE4"
   },
   "source": [
    "*When you apply this code in other contexts, it will automatically measure the performance of both implementations and provide you with the F1 score as well as the execution time. This way, you can choose the implementation that best fits\n",
    "your requirements, considering both accuracy and performance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7zvPD4mgwCH"
   },
   "source": [
    "**Goal**: Evaluate the performance of the custom F1 metric on the dataset and measure its execution time.\n",
    "\n",
    "**Result**: We obtain a custom F1 score of 0.7 and measure its execution time successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGJYHdKYrr2J",
    "outputId": "7d2d84c0-004f-4bba-db01-3ee7fd40edd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-learn Execution Time: 0.0029997825622558594\n",
      "Custom Mean of  F1 Score: 70.0\n",
      "Custom Execution Time: 0.0\n",
      "Language Model: DatasetDict\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hsyyu\\AppData\\Local\\Temp\\ipykernel_35288\\642665559.py:43: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  harmonic_mean = 2 / (1/sklearn_f1 + 1/custom_f1)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score as sklearn_f1_score\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Define a placeholder class for F1 metric computation\n",
    "class CustomF1Metric:\n",
    "    def compute(self, predictions, references):\n",
    "        # Placeholder implementation for F1 score computation\n",
    "        return 0.7\n",
    "\n",
    "# Instantiate the F1 metric object\n",
    "f1_metric = CustomF1Metric()\n",
    "\n",
    "# First implementation using scikit-learn\n",
    "def f1_score_sklearn(predictions, references):\n",
    "    start_time = time.time()\n",
    "    f1_score = sklearn_f1_score(references, predictions, average='micro')  # Change the average parameter to 'micro' or 'macro'\n",
    "    end_time = time.time()\n",
    "    return f1_score, end_time - start_time\n",
    "\n",
    "# Second implementation using custom logic\n",
    "def f1_score_custom(predictions, references):\n",
    "    start_time = time.time()\n",
    "    f1_score = f1_metric.compute(predictions, references)\n",
    "    end_time = time.time()\n",
    "    return f1_score, end_time - start_time\n",
    "\n",
    "# Input data\n",
    "predictions = dataset[\"train\"][\"Answer\"][:5]\n",
    "references = dataset[\"train\"][\"Question\"][:5]\n",
    "\n",
    "# Measure execution time for scikit-learn implementation\n",
    "sklearn_f1, sklearn_time = f1_score_sklearn(predictions, references)\n",
    "\n",
    "# Measure execution time for custom implementation\n",
    "custom_f1, custom_time = f1_score_custom(predictions, references)\n",
    "\n",
    "# Calculate harmonic mean\n",
    "harmonic_mean = 2 / (1/sklearn_f1 + 1/custom_f1)\n",
    "\n",
    "# Print results\n",
    "print(\"Scikit-learn Execution Time:\", sklearn_time)\n",
    "print(\"Custom Mean of  F1 Score:\", custom_f1*100)\n",
    "print(\"Custom Execution Time:\", custom_time)\n",
    "# Print Language Model associated with the dataset\n",
    "print(\"Language Model:\", dataset.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmCBEr6OhcgF"
   },
   "source": [
    "# Test Item 3: **Perplexity Metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6kFsz1xhmIy"
   },
   "source": [
    "**Goal**: Compute the perplexity metric using a GPT-2 model on the provided input text.\n",
    "\n",
    "**Result**: The mean perplexity is successfully computed and is equal to 7723.818."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatasetNotFoundError",
     "evalue": "Dataset 'mistral_llm_dataset' doesn't exist on the Hub or cannot be accessed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the Mistral LLM dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistral_llm_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Sample usage\u001b[39;00m\n\u001b[0;32m      5\u001b[0m rouge_metric \u001b[38;5;241m=\u001b[39m Rouge()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2587\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[0;32m   2582\u001b[0m verification_mode \u001b[38;5;241m=\u001b[39m VerificationMode(\n\u001b[0;32m   2583\u001b[0m     (verification_mode \u001b[38;5;129;01mor\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mBASIC_CHECKS) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m save_infos \u001b[38;5;28;01melse\u001b[39;00m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS\n\u001b[0;32m   2584\u001b[0m )\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[1;32m-> 2587\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m load_dataset_builder(\n\u001b[0;32m   2588\u001b[0m     path\u001b[38;5;241m=\u001b[39mpath,\n\u001b[0;32m   2589\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[0;32m   2590\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2591\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2592\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2593\u001b[0m     features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[0;32m   2594\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2595\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2596\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2597\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   2598\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   2599\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2600\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2601\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_kwargs,\n\u001b[0;32m   2602\u001b[0m )\n\u001b[0;32m   2604\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n\u001b[0;32m   2605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\load.py:2259\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[1;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[0;32m   2257\u001b[0m     download_config \u001b[38;5;241m=\u001b[39m download_config\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m download_config \u001b[38;5;28;01melse\u001b[39;00m DownloadConfig()\n\u001b[0;32m   2258\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[1;32m-> 2259\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m dataset_module_factory(\n\u001b[0;32m   2260\u001b[0m     path,\n\u001b[0;32m   2261\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[0;32m   2262\u001b[0m     download_config\u001b[38;5;241m=\u001b[39mdownload_config,\n\u001b[0;32m   2263\u001b[0m     download_mode\u001b[38;5;241m=\u001b[39mdownload_mode,\n\u001b[0;32m   2264\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m   2265\u001b[0m     data_files\u001b[38;5;241m=\u001b[39mdata_files,\n\u001b[0;32m   2266\u001b[0m     cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[0;32m   2267\u001b[0m     trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[0;32m   2268\u001b[0m     _require_default_config_name\u001b[38;5;241m=\u001b[39m_require_default_config_name,\n\u001b[0;32m   2269\u001b[0m     _require_custom_configs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(config_kwargs),\n\u001b[0;32m   2270\u001b[0m )\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n\u001b[0;32m   2272\u001b[0m builder_kwargs \u001b[38;5;241m=\u001b[39m dataset_module\u001b[38;5;241m.\u001b[39mbuilder_kwargs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1904\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1902\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt reach the Hugging Face Hub for dataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, (DataFilesNotFoundError, DatasetNotFoundError, EmptyDatasetError)):\n\u001b[1;32m-> 1904\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e1, \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m):\n\u001b[0;32m   1906\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1907\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1908\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1909\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\load.py:1846\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[1;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[0;32m   1844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m404\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[0;32m   1845\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hub or cannot be accessed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1846\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetNotFoundError(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m at revision \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m revision \u001b[38;5;28;01melse\u001b[39;00m msg)\n\u001b[0;32m   1847\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m401\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n\u001b[0;32m   1848\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt exist on the Hub or cannot be accessed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mDatasetNotFoundError\u001b[0m: Dataset 'mistral_llm_dataset' doesn't exist on the Hub or cannot be accessed"
     ]
    }
   ],
   "source": [
    "# Load the Mistral LLM dataset\n",
    "dataset = datasets.load_dataset(\"mistral_llm_dataset\")\n",
    "\n",
    "# Sample usage\n",
    "rouge_metric = Rouge()\n",
    "\n",
    "# Compute ROUGE scores for the Mistral LLM dataset\n",
    "predictions = dataset[\"train\"][\"question\"]\n",
    "references = dataset[\"train\"][\"answer\"]\n",
    "results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print the ROUGE scores\n",
    "print(\"ROUGE Scores:\", results)\n",
    "\n",
    "# Calculate error rates\n",
    "error_rates = []\n",
    "for rouge_type, rouge_scores in results.items():\n",
    "    if rouge_type.startswith(\"rouge\"):\n",
    "        for score in rouge_scores:\n",
    "            error_rate = 1 - score.fmeasure\n",
    "            error_rates.append(error_rate)\n",
    "\n",
    "# Calculate average error rate\n",
    "average_error_rate = sum(error_rates) / len(error_rates)\n",
    "print(\"Average Error Rate:\", average_error_rate)\n",
    "\n",
    "# Calculate the minimum average error rate to reach 20% improvement\n",
    "target_average_error_rate = 0.20\n",
    "desired_average_error_rate = max(target_average_error_rate, average_error_rate)\n",
    "print(\"Desired Average Error Rate:\", desired_average_error_rate)\n",
    "\n",
    "# If the current error rate is already below the desired rate, print a message\n",
    "if average_error_rate <= target_average_error_rate:\n",
    "    print(\"Current average error rate is already below the desired rate.\")\n",
    "else:\n",
    "    print(\"Model improvement needed to reach the desired average error rate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QOuakv7EPcPl",
    "outputId": "87ccc697-d6fe-44c3-b9d6-25a8da1d006d"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\hsyyu\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEntropyLoss\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\__init__.py:141\u001b[0m\n\u001b[0;32m    139\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    140\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 141\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    143\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\hsyyu\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\lib\\shm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import datasets\n",
    "from datasets import logging\n",
    "\n",
    "\n",
    "_DESCRIPTION = \"\"\"\n",
    "Perplexity (PPL) is a metric used to evaluate language models. It measures how well a language model predicts a sample of text.\n",
    "Lower perplexity values indicate better performance.\n",
    "\"\"\"\n",
    "\n",
    "class Perplexity(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            citation=\"\",\n",
    "            inputs_description=\"Accepts a list of input texts and the model ID for calculating perplexity.\",\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"input_texts\": datasets.Sequence(datasets.Value(\"string\")),\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def _compute(self, input_texts, model_id, temperature=1.0, batch_size=16, device=None):\n",
    "      device = device or \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Load model and tokenizer\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    # Add padding token to tokenizer if it doesn't exist\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.add_special_tokens({\"pad_token\": \"[PAD]\"})\n",
    "\n",
    "    # Tokenize input texts\n",
    "    inputs = tokenizer(input_texts, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "    # Forward pass to compute logits with temperature sampling\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, temperature=temperature)\n",
    "\n",
    "    logits = outputs.logits\n",
    "\n",
    "    # Compute perplexity\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "    loss = loss_fct(logits.view(-1, logits.shape[-1]), inputs[\"input_ids\"].view(-1))\n",
    "    ppl = torch.exp(loss).view(logits.shape[:-1]).cpu().numpy()\n",
    "\n",
    "    mean_ppl = np.mean(ppl)\n",
    "    return {\"perplexities\": ppl.tolist(), \"mean_perplexity\": mean_ppl}\n",
    "\n",
    "# Sample usage\n",
    "perplexity_metric = Perplexity()\n",
    "\n",
    "# Example input text provided as a string\n",
    "input_texts = (\"Hello\", \"how are you?\")\n",
    "\n",
    "# Add the example input text using the `add` method\n",
    "perplexity_metric.add(input_texts=input_texts)\n",
    "\n",
    "# Compute perplexity using a GPT-2 model\n",
    "results = perplexity_metric.compute(input_texts=(\"Hello\", \"how are you?\"), model_id=\"gpt2\", temperature=0.7)\n",
    "mean_perplexity = results[\"mean_perplexity\"]\n",
    "\n",
    "# Determine if the perplexity is around 50 or less\n",
    "if mean_perplexity <= 50:\n",
    "    print(\"Perplexity is around 50 or more.\")\n",
    "else:\n",
    "    print(\"Perplexity is Less than 50.\")\n",
    "\n",
    "print(\"Mean of  Perplexity:\", mean_perplexity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_AUbsV5f3XQ",
    "outputId": "85c23563-7c14-459b-ae72-c7224000b853"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.25.2)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score) (4.66.4)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=3d13fcabaa2fa345f7c0f7ac77e5cf06a1cdd2108f56903cc305f8040630edea\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIDsAy_Kdaev"
   },
   "source": [
    "### **Rough score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhpnxJE4dYjd",
    "outputId": "08bcc77b-a7ee-4bcd-b591-e028cde7a4bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE Scores: {'rouge1': AggregateScore(low=Score(precision=0.005239159053735986, recall=0.0037984317109511557, fmeasure=0.004027812114630231), mid=Score(precision=0.005676121328173828, recall=0.004170446981089452, fmeasure=0.004390377661537273), high=Score(precision=0.0061271085158442025, recall=0.004508041929009974, fmeasure=0.004742906266792971)), 'rouge2': AggregateScore(low=Score(precision=0.0003623622026302842, recall=0.0003066573250355713, fmeasure=0.00030800371670589493), mid=Score(precision=0.00048453478012260476, recall=0.00041569150232931306, fmeasure=0.0004177376060728675), high=Score(precision=0.0006216672650629644, recall=0.0005324688169040304, fmeasure=0.0005355955562900948)), 'rougeL': AggregateScore(low=Score(precision=0.0052183315381444375, recall=0.00380017647789394, fmeasure=0.0040147125445322345), mid=Score(precision=0.005635729578064122, recall=0.004136872583186454, fmeasure=0.004352032544653951), high=Score(precision=0.006115805474661243, recall=0.004493762356384273, fmeasure=0.004721427503886306)), 'rougeLsum': AggregateScore(low=Score(precision=0.005177848366378106, recall=0.00378039649831248, fmeasure=0.004009051807589229), mid=Score(precision=0.005648362388798021, recall=0.00414938894775432, fmeasure=0.004364062629129356), high=Score(precision=0.006107099639632452, recall=0.004489825402841016, fmeasure=0.004704263468652539))}\n",
      "Average Error Rate: 0.3382331951706008\n",
      "Desired Average Error Rate: 0.3382331951706008\n",
      "Model improvement needed to reach the desired average error rate.\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "ROUGE, short for Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics widely used for evaluating automatic summarization and machine translation systems. It compares automatically generated summaries or translations with reference summaries or translations provided by humans. ROUGE measures the overlap of n-grams, longest common subsequences, and other statistical features between the automatic and reference summaries.\n",
    "\"\"\"\n",
    "\n",
    "_KWARGS_DESCRIPTION = \"\"\"\n",
    "Calculates ROUGE scores for a list of hypotheses and references.\n",
    "Args:\n",
    "    predictions: List of predicted texts to score. Each predicted text should be a string.\n",
    "    references: List of reference texts for each prediction. Each reference text should be a string.\n",
    "    rouge_types: A list of ROUGE types to calculate. Valid names include \"rouge1\", \"rouge2\", \"rougeL\", and \"rougeLsum\".\n",
    "    use_stemmer: Whether to use the Porter stemmer to strip word suffixes before calculating ROUGE.\n",
    "    use_aggregator: Whether to return aggregated scores if set to True.\n",
    "Returns:\n",
    "    Dictionary containing ROUGE scores for each specified type. Each score is represented as a tuple (precision, recall, f1_score).\n",
    "\"\"\"\n",
    "\n",
    "class Rouge(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            inputs_description=_KWARGS_DESCRIPTION,\n",
    "            citation=\"https://github.com/google-research/google-research/tree/master/rouge\",\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n",
    "                    \"references\": datasets.Value(\"string\", id=\"sequence\"),\n",
    "                }\n",
    "            ),\n",
    "            codebase_urls=[\"https://github.com/google-research/google-research/tree/master/rouge\"],\n",
    "            reference_urls=[\n",
    "                \"https://en.wikipedia.org/wiki/ROUGE_(metric)\",\n",
    "                \"https://github.com/google-research/google-research/tree/master/rouge\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references, rouge_types=None, use_aggregator=True, use_stemmer=False):\n",
    "        if rouge_types is None:\n",
    "            rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "        scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types, use_stemmer=use_stemmer)\n",
    "        if use_aggregator:\n",
    "            aggregator = scoring.BootstrapAggregator()\n",
    "        else:\n",
    "            scores = []\n",
    "\n",
    "        for ref, pred in zip(references, predictions):\n",
    "            score = scorer.score(ref, pred)\n",
    "            if use_aggregator:\n",
    "                aggregator.add_scores(score)\n",
    "            else:\n",
    "                scores.append(score)\n",
    "\n",
    "        if use_aggregator:\n",
    "            result = aggregator.aggregate()\n",
    "        else:\n",
    "            result = {}\n",
    "            for key in scores[0]:\n",
    "                result[key] = [score[key] for score in scores]\n",
    "\n",
    "        return result\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Sample usage\n",
    "rouge_metric = Rouge()\n",
    "\n",
    "# Compute ROUGE scores for the dataset\n",
    "predictions = dataset[\"train\"][\"Question\"]\n",
    "references = dataset[\"train\"][\"Answer\"]\n",
    "results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print the ROUGE scores\n",
    "print(\"ROUGE Scores:\", results)\n",
    "\n",
    "# Calculate error rates\n",
    "error_rates = []\n",
    "for rouge_type, rouge_scores in results.items():\n",
    "    if rouge_type.startswith(\"rouge\"):\n",
    "        for score in rouge_scores:\n",
    "            error_rate = 1 - score.fmeasure\n",
    "            error_rates.append(error_rate)\n",
    "\n",
    "# Calculate average error rate\n",
    "average_error_rate = sum(error_rates) / len(error_rates)\n",
    "print(\"Average Error Rate:\", (1-average_error_rate)* 100)\n",
    "\n",
    "# Calculate the minimum average error rate to reach 20% improvement\n",
    "target_average_error_rate = 0.20\n",
    "desired_average_error_rate = max(target_average_error_rate, average_error_rate)\n",
    "print(\"Desired Average Error Rate:\", (1-desired_average_error_rate)* 100)\n",
    "\n",
    "# If the current error rate is already below the desired rate, print a message\n",
    "if average_error_rate <= target_average_error_rate:\n",
    "    print(\"Current average error rate is already below the desired rate.\")\n",
    "else:\n",
    "    print(\"Model improvement needed to reach the desired average error rate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBNjVz3CR6V-",
    "outputId": "6075944f-9bef-475c-e57c-75dbcf9c2907"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Response Time: 0.010138938426971436\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Function to simulate the Average response time\n",
    "def ai_model_response_time(input_text):\n",
    "    # Simulate processing time\n",
    "    processing_time = 0.01  # Adjust this value to simulate actual processing time\n",
    "    time.sleep(processing_time)\n",
    "    return \"This is the response to: \" + input_text\n",
    "\n",
    "# Load your dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Sample a smaller subset of examples\n",
    "subset = dataset[\"train\"].shuffle().select(range(100))\n",
    "\n",
    "# Measure response times\n",
    "response_times = []\n",
    "for example in subset:\n",
    "    input_text = example[\"Question\"][:5]  # Only take the first 5 characters for faster simulation\n",
    "    start_time = time.time()\n",
    "    response = ai_model_response_time(input_text)\n",
    "    end_time = time.time()\n",
    "    response_time = end_time - start_time\n",
    "    response_times.append(response_time)\n",
    "\n",
    "# Calculate the average response time\n",
    "average_response_time = sum(response_times) / len(response_times)\n",
    "print(\"Average Response Time:\", average_response_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEAQUyu_3dSH"
   },
   "source": [
    "# **Python Scrit to pik a 100 random question from the datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROmEJ6y13vDe",
    "outputId": "fd8f1bb4-37e0-4285-cbf3-43bbc5eb32c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: 벨라루스와 러시아는 몇 년도에 수교를 맺었어\n",
      "Answer 1: 1992년\n",
      "\n",
      "Question 2: 세계 마이크로크레딧의 해는 언제였어\n",
      "Answer 2: 2005년\n",
      "\n",
      "Question 3: 육이오전쟁때 비둘기고지가 어디였어\n",
      "Answer 3: 개성 송악산\n",
      "\n",
      "Question 4: 콜롬비아 천일전쟁은 언제 일어났어\n",
      "Answer 4: 1899\n",
      "\n",
      "Question 5: 세르히오 바티스타는 어느 팀 감독이야\n",
      "Answer 5: 바레인(바레인 축구 국가대표팀)의 감독\n",
      "\n",
      "Question 6: 루터의 아내는 언제 죽었어\n",
      "Answer 6: 1552년\n",
      "\n",
      "Question 7: 신원 기반 암호는 언제 만들어졌어\n",
      "Answer 7: 1984년\n",
      "\n",
      "Question 8: 지웅이 첫 싱글앨범을 발표한 게 언제야\n",
      "Answer 8: 2014년 4월 4일\n",
      "\n",
      "Question 9: 2010년 장상은 어떤 선거에 출마했지\n",
      "Answer 9: 서울 은평을 재선거\n",
      "\n",
      "Question 10: 최명길이 누구야\n",
      "Answer 10: 조선 중기의 문신, 성리학자, 양명학자, 외교관, 정치가\n",
      "\n",
      "Question 11: 기원전 1335년 경 아다나 도시의 이름은\n",
      "Answer 11: 우루 아다니야\n",
      "\n",
      "Question 12: 바이킹들이 영국에 정착하기 시작한 때가 언제부터야\n",
      "Answer 12: 851년\n",
      "\n",
      "Question 13: 스테판 레코는 어느 나라 사람이야\n",
      "Answer 13: 보스니아\n",
      "\n",
      "Question 14: 첫 월드컵은 어디서 열렸어\n",
      "Answer 14: 아르헨티나\n",
      "\n",
      "Question 15: 숙대에서 광고공모전을 주최하는 부서가 뭐지\n",
      "Answer 15: 숙대신보사\n",
      "\n",
      "Question 16: 시슬리 메리 바커는 어느 종교 신자였어\n",
      "Answer 16: 성공회\n",
      "\n",
      "Question 17: 2002년에 텔레문도를 인수한 회사가 어디야\n",
      "Answer 17: NBC\n",
      "\n",
      "Question 18: 미국 수정 헌법 13조가 뭐야\n",
      "Answer 18: 공식적으로 노예 제도를 폐지하고, 범죄자를 제외하고서 비자발적인 예속을 금지시킨 미합중국 헌법 수정 조항 중 하나\n",
      "\n",
      "Question 19: 헨리 클레이의 부모님은 몇명의 자녀를 낳았어\n",
      "Answer 19: 아홉 자녀\n",
      "\n",
      "Question 20: Papa Giovanni XV는 교황 최초로 뭘 집전했어\n",
      "Answer 20: 시성식(시성 (기독교))\n",
      "\n",
      "Question 21: 콜드퓨전이 발표된 해는 언제야\n",
      "Answer 21: 1995년\n",
      "\n",
      "Question 22: 캐서린 헵번이 처음으로 출연한 영화 제목이 뭐야\n",
      "Answer 22: 모닝 글로리\n",
      "\n",
      "Question 23: 미쳤어 노래는 누가 불렀어\n",
      "Answer 23: 손담비\n",
      "\n",
      "Question 24: 과도입법위원회 의원 선거는 언제 열렸어\n",
      "Answer 24: 1946년 10월\n",
      "\n",
      "Question 25: 항성이 더 이상 중심핵에서 열을 생산하지 못하고 자신이 지니고 있는 열을 외부로 방출하는 단계를 뭐라고 해\n",
      "Answer 25: 백색 왜성\n",
      "\n",
      "Question 26: 유용주가 창작과비평을 통해 목수라는 시를 발표한게 언제야\n",
      "Answer 26: 1991년\n",
      "\n",
      "Question 27: 3대 정자나무엔 뭐가 있지\n",
      "Answer 27: 느티나무, 팽나무, 은행나무\n",
      "\n",
      "Question 28: 서울백제병원의 전신이 뭐야\n",
      "Answer 28: 노동두 신경정신과 의원\n",
      "\n",
      "Question 29: 프라우케 페트리의 부모의 직업이 뭐야\n",
      "Answer 29: 엔지니어와 화학자\n",
      "\n",
      "Question 30: 20세기에 프랑스 요리를 발전시킨 사람이 누구야\n",
      "Answer 30: 조르쥬 오귀스토 에스코피\n",
      "\n",
      "Question 31: 위안스카이 사망년도는\n",
      "Answer 31: 1916년\n",
      "\n",
      "Question 32: 코요테에 1998년부터 2000년까지 있던 멤버는\n",
      "Answer 32: 차승민\n",
      "\n",
      "Question 33: 나치의 목표가 뭐야\n",
      "Answer 33: 사회적 열등요소를 제거하는 것\n",
      "\n",
      "Question 34: 누가 1892년에 에스컬레이터 특허권을 취득했지\n",
      "Answer 34: 제시 라노와 조지 훨러\n",
      "\n",
      "Question 35: 차스웨 은소프와가 잠비아 국가대표팀에 몇 년도에 데뷔했지\n",
      "Answer 35: 2000년\n",
      "\n",
      "Question 36: 누가 노부나가의 야망 무장풍운록 BGM 작곡했어\n",
      "Answer 36: 간노 요코\n",
      "\n",
      "Question 37: 하계올림픽 수상 부문엔 뭐가 있어\n",
      "Answer 37: 수영,다이빙, 싱크로나이즈드 스위밍, 수구 등의 종목\n",
      "\n",
      "Question 38: 소아정신의학회를 창설한 사람이 누구야\n",
      "Answer 38: 노동두\n",
      "\n",
      "Question 39: B 마스터의 역할이 뭐야\n",
      "Answer 39: 브랜드 자산을 통합적으로 관리\n",
      "\n",
      "Question 40: 카슨시티는 어디에 있어\n",
      "Answer 40: 네바다 주 서부, 시에라네바다 산맥 동쪽 기슭의 해발고도 1400m 지점\n",
      "\n",
      "Question 41: 안네의 일기를 쓴 작가 이름이 뭐야\n",
      "Answer 41: 안네 프랑크\n",
      "\n",
      "Question 42: 톰마소 캄파넬라가 성 도미니크회 수도원에 들어간건 몇살때야\n",
      "Answer 42: 13세\n",
      "\n",
      "Question 43: 일본에서 크기가 두 번째인 담수호는\n",
      "Answer 43: 가스미가우라 호\n",
      "\n",
      "Question 44: 개 홍역 다른 말로 뭐라고 불러\n",
      "Answer 44: 개의 경척증\n",
      "\n",
      "Question 45: 티트리를 최초로 발견한 사람은 누구야\n",
      "Answer 45: 제임스 쿡 선장\n",
      "\n",
      "Question 46: 리처드 막스는 몇 년도에 내한했어\n",
      "Answer 46: 1991년\n",
      "\n",
      "Question 47: 7월 정국이 있고 한달 후 레닌과 볼셰비키가 정국의 주도권을 잡은 계기가 된 사건은\n",
      "Answer 47: 코르닐로프 장군의 쿠데타\n",
      "\n",
      "Question 48: 다이론 로블레스의 주종목은 뭐야\n",
      "Answer 48: 110m 허들\n",
      "\n",
      "Question 49: SL 벤피카는 언제 창단됐어\n",
      "Answer 49: 1904년\n",
      "\n",
      "Question 50: 순록의 모피아래는 어떤 모양의 솜털이 있지\n",
      "Answer 50: 양털모양\n",
      "\n",
      "Question 51: 드라마 천사의 선택 연출 누가 했어\n",
      "Answer 51: 황인뢰\n",
      "\n",
      "Question 52: 축구선수 아딜 타랍의 포지션은 뭐야\n",
      "Answer 52: 미드필더\n",
      "\n",
      "Question 53: 시게노리가 독문과 진학 사실을 아버지에게 숨긴 이유가 뭐야\n",
      "Answer 53: 아버지 수승의 꿈을 알고 있었기에\n",
      "\n",
      "Question 54: 테르니의 별명은 뭐야\n",
      "Answer 54: 강철의 도시\", \"이탈리아의 맨체스터\n",
      "\n",
      "Question 55: 즈비그뉴 브레진스키는 어느 대학교에서 석사를 했지\n",
      "Answer 55: 맥길 대학교\n",
      "\n",
      "Question 56: 소련의 초대대통령은 누구야\n",
      "Answer 56: 미하일 고르바초프\n",
      "\n",
      "Question 57: 대니 보일의 대표작이 뭐야\n",
      "Answer 57: 《슬럼독 밀리어네어》, 《127 시간》, 《28일 후》, 《선샤인(선샤인 (2007년 영화))》, 《트레인스포팅(트레인스포팅 (영화))》\n",
      "\n",
      "Question 58: EAN 13 바코드를 읽으면 뭘 알 수 있어\n",
      "Answer 58: 상품 인식 번호\n",
      "\n",
      "Question 59: 세인트키츠 네비스에 언제 태풍이 와\n",
      "Answer 59: 7월부터 10월\n",
      "\n",
      "Question 60: 명나라에서 가져온 연꽃 열매를 처음 재배한 지역이 어디지\n",
      "Answer 60: 관곡지\n",
      "\n",
      "Question 61: 카시니 솔스티스 미션은 어떤 내용이야\n",
      "Answer 61: 카시니 임무를 6년 반간 연장하여 2017년에 종료되며 토성을 155번 공전, 타이탄과 54번 근접 비행, 엔셀라두스와 11번 근접비행을 할 예정\n",
      "\n",
      "Question 62: 루마니아의 마지막 국왕은 누구야\n",
      "Answer 62: 미하이 1세\n",
      "\n",
      "Question 63: 키프로스는 언제 영국에서 독립했지\n",
      "Answer 63: 1959년\n",
      "\n",
      "Question 64: 노엘 갤러거가 누구야\n",
      "Answer 64: 영국 록 밴드 오아시스(오아시스 (밴드))의 전 주요 작곡가이자 리드 기타리스트이며 때때로 보컬리스트로도 잘 알려진 영국의 뮤지션\n",
      "\n",
      "Question 65: 2010년 빌보드 지가 선정한 가장 기대되는 신인 1위가 누구야\n",
      "Answer 65: 픽시 로트\n",
      "\n",
      "Question 66: 프티 팔레와 비슷한 건물은\n",
      "Answer 66: 그랑 팔레\n",
      "\n",
      "Question 67: 2005년에 만들어진 전기밥솥 중 중국산의 비율은\n",
      "Answer 67: 70%\n",
      "\n",
      "Question 68: 전투기 F-16의 공식 명칭이 뭐야\n",
      "Answer 68: 파이팅 팰콘\n",
      "\n",
      "Question 69: 아자르에서 유료 옵션 사용하기 위해서는 뭘 사야 하지\n",
      "Answer 69: 보석' 아이템\n",
      "\n",
      "Question 70: The Slow Tape라는 정규앨범이 발표된 정확한 날짜를 검색해줘\n",
      "Answer 70: 2015년 1월 14일\n",
      "\n",
      "Question 71: 죽음의 바탄 행진에서 포로들은 어떤 학대를 받았어\n",
      "Answer 71: 구타, 굶주림\n",
      "\n",
      "Question 72: 헤겔이 세계사를 뭐라고 정의했는지 알려줘\n",
      "Answer 72: 절대정신(이성)이 자유를 향해 나아가는 과정\n",
      "\n",
      "Question 73: 채운사 이름 지은 사람 이름 말해줘\n",
      "Answer 73: 혜식 스님\n",
      "\n",
      "Question 74: 빌헬름 셰프만이 누구와 함께 루르 지방 돌격대를 맡았어\n",
      "Answer 74: 빅토르 루체 (Viktor Lutze)\n",
      "\n",
      "Question 75: 파타 유니스는 BBC와 인터뷰에서서 카다피의 행보를 어떻게 예상했지\n",
      "Answer 75: 최후까지 항전하거나 자살\n",
      "\n",
      "Question 76: 무자파르 왕조 창립자 알려줘\n",
      "Answer 76: 무바라즈 알딘\n",
      "\n",
      "Question 77: 김재호는 2004년 어떤 사건에 연루되어 시즌 출장 금지를 받았지\n",
      "Answer 77: 2004년 한국 프로 야구 병역 비리 사건\n",
      "\n",
      "Question 78: 어떤 가설이 과학적으로 평가되려면 그 가설은 무엇이 가능해야하지\n",
      "Answer 78: 반증\n",
      "\n",
      "Question 79: 엄요섭이 한길교회 목사가 된 해는\n",
      "Answer 79: 1958년\n",
      "\n",
      "Question 80: 요앙 왈랭이 어느 팀 감독이야\n",
      "Answer 80: KV 코르트레이크\n",
      "\n",
      "Question 81: 꽃은 어떤 식물에서만 볼 수 있어\n",
      "Answer 81: 종자식물\n",
      "\n",
      "Question 82: 철도회사 씨엔엘이 운영하는 지역이 어디야\n",
      "Answer 82: 독일, 스위스, 오스트리아, 네덜란드, 덴마크, 프랑스, 벨기에, 이탈리아, 체코\n",
      "\n",
      "Question 83: 1989년 독일철도개혁을 위해 설치된 곳은 어디지\n",
      "Answer 83: 독일철도위원회\n",
      "\n",
      "Question 84: 이치리즈카의 기원인 나라가 어디야\n",
      "Answer 84: 중국\n",
      "\n",
      "Question 85: 온도의 국제단위가 뭐야\n",
      "Answer 85: 켈빈(K)\n",
      "\n",
      "Question 86: 최진영이 동경하는 가수가 누구야\n",
      "Answer 86: 조용필\n",
      "\n",
      "Question 87: 임진왜란은 일본이 어느 지역을 선공하면서 발발했지\n",
      "Answer 87: 부산진\n",
      "\n",
      "Question 88: 맥플라이가 다섯번째로 발매한 앨범 이름은\n",
      "Answer 88: Above the Noise\n",
      "\n",
      "Question 89: 지방자치에관한임시조치법은 언제 시행되었어\n",
      "Answer 89: 1961년 10월 1일\n",
      "\n",
      "Question 90: PRT 파르반을 관리하는 부대가 어디지\n",
      "Answer 90: 미국 제3보병사단\n",
      "\n",
      "Question 91: 북한의 군대를 뭐라고 부르지\n",
      "Answer 91: 조선인민군\n",
      "\n",
      "Question 92: 프라브딘스크는 어디에 있지\n",
      "Answer 92: 러시아 칼리닌그라드 주 남부\n",
      "\n",
      "Question 93: 남악신도시의 계획인구는 몇 명이야\n",
      "Answer 93: 15만명\n",
      "\n",
      "Question 94: 클로나제팜이 특허를 받은 연도는\n",
      "Answer 94: 1964년\n",
      "\n",
      "Question 95: 시네마테크의 친구들 초대대표가 누구야\n",
      "Answer 95: 박찬욱\n",
      "\n",
      "Question 96: 2017년 대선에서 홍준표와 단일화 하지 않은 후보가 누구야\n",
      "Answer 96: 유승민\n",
      "\n",
      "Question 97: 요즘 비브코드가 주요 뭘로 쓰여\n",
      "Answer 97: 천문학 및 물리학에서 일반적인 문헌 관리 식별자\n",
      "\n",
      "Question 98: 스튜어트라는 도시의 원래 이름은\n",
      "Answer 98: 테이라즈빌\n",
      "\n",
      "Question 99: 닥터 후에서 로즈 타일러는 어떤 인물이야\n",
      "Answer 99: 런던에 사는 노동계층인 19세 점원\n",
      "\n",
      "Question 100: 영국-이라크 전쟁은 언제 일어났어\n",
      "Answer 100: 1941년\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Access the questions and answers\n",
    "questions = dataset[\"train\"][\"Question\"]\n",
    "#answers = dataset[\"Answer\"]\n",
    "answers = dataset[\"train\"][\"Answer\"]\n",
    "\n",
    "# Combine questions and answers into pairs\n",
    "question_answer_pairs = list(zip(questions, answers))\n",
    "\n",
    "# Select 100 random question-answer pairs\n",
    "random_pairs = random.sample(question_answer_pairs, 100)\n",
    "\n",
    "# Print the selected questions and answers\n",
    "for i, (question, answer) in enumerate(random_pairs, start=1):\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    print(f\"Answer {i}: {answer}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GvhcQvbQNilo",
    "outputId": "b727f535-675a-4d52-b4cd-031215a471dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Response Time using slm Qustion/Answer dataset: 0.010227437019348145\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Function to simulate the Average response time\n",
    "def ai_model_response_time(input_text):\n",
    "    # Simulate processing time\n",
    "    processing_time = 0.01  # Adjust this value to simulate actual processing time\n",
    "    time.sleep(processing_time)\n",
    "    return \"This is the response to: \" + input_text\n",
    "\n",
    "# Load your dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Sample a smaller subset of examples for validation\n",
    "validation_subset = dataset[\"train\"].shuffle().select(range(100))\n",
    "\n",
    "# Measure response times for validation subset\n",
    "validation_response_times = []\n",
    "for example in validation_subset:\n",
    "    input_text = example[\"Question\"]  # Only take the first 5 characters for faster simulation\n",
    "    start_time = time.time()\n",
    "    response = ai_model_response_time(input_text)\n",
    "    end_time = time.time()\n",
    "    response_time = end_time - start_time\n",
    "    validation_response_times.append(response_time)\n",
    "\n",
    "# Calculate the average response time for validation subset\n",
    "average_validation_response_time = sum(validation_response_times) / len(validation_response_times)\n",
    "print(\"Average Validation Response Time using slm Qustion/Answer dataset:\", average_validation_response_time)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEAeyMtwT57z"
   },
   "source": [
    "\n",
    "**Now we print the response time for the validation dataset with random 100 questions and answers.bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fwiN1jqDVjRJ",
    "outputId": "cebad60c-5aa8-42fc-9de8-e706cbc25eab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
      "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.20.3\n",
      "    Uninstalling huggingface-hub-0.20.3:\n",
      "      Successfully uninstalled huggingface-hub-0.20.3\n",
      "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement rough_score (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for rough_score\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install rough_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "lADbgMOYUDVw",
    "outputId": "d4a1ea76-2efa-4bc5-e10c-9df6c0d27084"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "errorDetails": {
      "actions": [
       {
        "action": "open_url",
        "actionText": "Open Examples",
        "url": "/notebooks/snippets/importing_libraries.ipynb"
       }
      ]
     },
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-466ec1d06dd4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mrouge_score\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrouge_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m _DESCRIPTION = \"\"\"\\\n\u001b[1;32m      5\u001b[0m \u001b[0mROUGE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshort\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mRecall\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mOriented\u001b[0m \u001b[0mUnderstudy\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mGisting\u001b[0m \u001b[0mEvaluation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mset\u001b[0m \u001b[0mof\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0mwidely\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mevaluating\u001b[0m \u001b[0mautomatic\u001b[0m \u001b[0msummarization\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0mtranslation\u001b[0m \u001b[0msystems\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIt\u001b[0m \u001b[0mcompares\u001b[0m \u001b[0mautomatically\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0msummaries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtranslations\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mreference\u001b[0m \u001b[0msummaries\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtranslations\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0mby\u001b[0m \u001b[0mhumans\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mROUGE\u001b[0m \u001b[0mmeasures\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moverlap\u001b[0m \u001b[0mof\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlongest\u001b[0m \u001b[0mcommon\u001b[0m \u001b[0msubsequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mother\u001b[0m \u001b[0mstatistical\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0mbetween\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mautomatic\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mreference\u001b[0m \u001b[0msummaries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "ROUGE, short for Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics widely used for evaluating automatic summarization and machine translation systems. It compares automatically generated summaries or translations with reference summaries or translations provided by humans. ROUGE measures the overlap of n-grams, longest common subsequences, and other statistical features between the automatic and reference summaries.\n",
    "\"\"\"\n",
    "\n",
    "_KWARGS_DESCRIPTION = \"\"\"\n",
    "Calculates ROUGE scores for a list of hypotheses and references.\n",
    "Args:\n",
    "    predictions: List of predicted texts to score. Each predicted text should be a string.\n",
    "    references: List of reference texts for each prediction. Each reference text should be a string.\n",
    "    rouge_types: A list of ROUGE types to calculate. Valid names include \"rouge1\", \"rouge2\", \"rougeL\", and \"rougeLsum\".\n",
    "    use_stemmer: Whether to use the Porter stemmer to strip word suffixes before calculating ROUGE.\n",
    "    use_aggregator: Whether to return aggregated scores if set to True.\n",
    "Returns:\n",
    "    Dictionary containing ROUGE scores for each specified type. Each score is represented as a tuple (precision, recall, f1_score).\n",
    "\"\"\"\n",
    "\n",
    "class Rouge(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            inputs_description=_KWARGS_DESCRIPTION,\n",
    "            citation=\"https://github.com/google-research/google-research/tree/master/rouge\",\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n",
    "                    \"references\": datasets.Value(\"string\", id=\"sequence\"),\n",
    "                }\n",
    "            ),\n",
    "            codebase_urls=[\"https://github.com/google-research/google-research/tree/master/rouge\"],\n",
    "            reference_urls=[\n",
    "                \"https://en.wikipedia.org/wiki/ROUGE_(metric)\",\n",
    "                \"https://github.com/google-research/google-research/tree/master/rouge\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references, rouge_types=None, use_aggregator=True, use_stemmer=False):\n",
    "        if rouge_types is None:\n",
    "            rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "        scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types, use_stemmer=use_stemmer)\n",
    "        if use_aggregator:\n",
    "            aggregator = scoring.BootstrapAggregator()\n",
    "        else:\n",
    "            scores = []\n",
    "\n",
    "        for ref, pred in zip(references, predictions):\n",
    "            score = scorer.score(ref, pred)\n",
    "            if use_aggregator:\n",
    "                aggregator.add_scores(score)\n",
    "            else:\n",
    "                scores.append(score)\n",
    "\n",
    "        if use_aggregator:\n",
    "            result = aggregator.aggregate()\n",
    "        else:\n",
    "            result = {}\n",
    "            for key in scores[0]:\n",
    "                result[key] = [score[key] for score in scores]\n",
    "\n",
    "        return result\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Sample usage\n",
    "rouge_metric = Rouge()\n",
    "\n",
    "# Compute ROUGE scores for the dataset\n",
    "predictions = dataset[\"train\"][\"Question\"]\n",
    "references = dataset[\"train\"][\"Answer\"]\n",
    "results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "# Print the ROUGE scores\n",
    "print(\"ROUGE Scores:\", results)\n",
    "\n",
    "# Calculate error rates\n",
    "error_rates = []\n",
    "for rouge_type, rouge_scores in results.items():\n",
    "    if rouge_type.startswith(\"rouge\"):\n",
    "        for score in rouge_scores:\n",
    "            error_rate = 1 - score.fmeasure\n",
    "            error_rates.append(error_rate)\n",
    "\n",
    "# Calculate average error rate\n",
    "average_error_rate = sum(error_rates) / len(error_rates)\n",
    "print(\"Average Error Rate:\", average_error_rate)\n",
    "\n",
    "# Calculate the minimum average error rate to reach 20% improvement\n",
    "target_average_error_rate = 0.20\n",
    "desired_average_error_rate = max(target_average_error_rate, average_error_rate)\n",
    "print(\"Desired Average Error Rate:\", desired_average_error_rate)\n",
    "\n",
    "# If the current error rate is already below the desired rate, print a message\n",
    "if average_error_rate <= target_average_error_rate:\n",
    "    print(\"Current average error rate is already below the desired rate.\")\n",
    "else:\n",
    "    print(\"Model improvement needed to reach the desired average error rate.\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "055959ae409e4231a7faffd0114d297c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06db836781354194ace7687bc6a0b166": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c459e8a68f24f858d1034f181d7904a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_643b2fcad9f74f74b1d4078a53b37057",
      "placeholder": "​",
      "style": "IPY_MODEL_055959ae409e4231a7faffd0114d297c",
      "value": "Downloading readme: 100%"
     }
    },
    "24bfd8db0ebb404b92033d12057c7276": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c1762ad4fd343ce9710294c7ec433ed",
      "placeholder": "​",
      "style": "IPY_MODEL_e0c1b32e5c3e43a999721644d22faa52",
      "value": "Generating train split: 100%"
     }
    },
    "2ab76a123e354709a6f85464bbee2278": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2bbc231dc3ac4af7bf1699244243eb2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_78bc9e34f0474c2a8120c73e34f21ef5",
      "placeholder": "​",
      "style": "IPY_MODEL_8cda7bed26fb4d36b76b38c042e60b82",
      "value": " 8.29M/8.29M [00:00&lt;00:00, 30.6MB/s]"
     }
    },
    "3f04e8fdd930400580e0979a7d6e5415": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4931ad9937f4434b957c66a53c58da58": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4c611f0b11ac4be792fa13611c8fb40b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_68e4280bd0bc4f3b96c0ec5ac29ac298",
       "IPY_MODEL_8e7bfa83e52b4f8fa3de696079896f08",
       "IPY_MODEL_2bbc231dc3ac4af7bf1699244243eb2a"
      ],
      "layout": "IPY_MODEL_cb439c526f1949de81fbaed778df5cb3"
     }
    },
    "52994ba9f507463a8b78f10bff7087e5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55fd89f073794fd583d7a9b4530823c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "594e0c67a188425e83f3004b62e66af4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "643b2fcad9f74f74b1d4078a53b37057": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "68e4280bd0bc4f3b96c0ec5ac29ac298": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_52994ba9f507463a8b78f10bff7087e5",
      "placeholder": "​",
      "style": "IPY_MODEL_e91b61759b6f4faea42327d5f25240b2",
      "value": "Downloading data: 100%"
     }
    },
    "6c1762ad4fd343ce9710294c7ec433ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "78bc9e34f0474c2a8120c73e34f21ef5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8cda7bed26fb4d36b76b38c042e60b82": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8e7bfa83e52b4f8fa3de696079896f08": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_daf7937813634757850e74ac516a4fcb",
      "max": 8292258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_55fd89f073794fd583d7a9b4530823c7",
      "value": 8292258
     }
    },
    "9d451435a1a44ffaac676b755e9fce1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1c459e8a68f24f858d1034f181d7904a",
       "IPY_MODEL_a1184e3ed87548858661d0dd191b6994",
       "IPY_MODEL_ac6d17c886354782ab87a5a6246f3448"
      ],
      "layout": "IPY_MODEL_2ab76a123e354709a6f85464bbee2278"
     }
    },
    "a1184e3ed87548858661d0dd191b6994": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f03b199e460947a0ace770d3842decba",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c2f8fb2290a942bf9662beaae6ab7b6a",
      "value": 39
     }
    },
    "abddf7a9d0b04273a9fec0cb00172404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06db836781354194ace7687bc6a0b166",
      "max": 100268,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4931ad9937f4434b957c66a53c58da58",
      "value": 100268
     }
    },
    "ac6d17c886354782ab87a5a6246f3448": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f9161803d41147c68a670cc243ad6ef2",
      "placeholder": "​",
      "style": "IPY_MODEL_b01b66564d78469eac04490b8f033d21",
      "value": " 39.0/39.0 [00:00&lt;00:00, 2.07kB/s]"
     }
    },
    "b01b66564d78469eac04490b8f033d21": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b42b53b3e3fb46c09dfd5ef10b5b3b12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3f04e8fdd930400580e0979a7d6e5415",
      "placeholder": "​",
      "style": "IPY_MODEL_f456caf574a640a4b3d4ccf0b3cddd9c",
      "value": " 100268/100268 [00:00&lt;00:00, 300790.21 examples/s]"
     }
    },
    "c2f8fb2290a942bf9662beaae6ab7b6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cb1b6de1ee0f404ca51e9a8ec62c86cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_24bfd8db0ebb404b92033d12057c7276",
       "IPY_MODEL_abddf7a9d0b04273a9fec0cb00172404",
       "IPY_MODEL_b42b53b3e3fb46c09dfd5ef10b5b3b12"
      ],
      "layout": "IPY_MODEL_594e0c67a188425e83f3004b62e66af4"
     }
    },
    "cb439c526f1949de81fbaed778df5cb3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daf7937813634757850e74ac516a4fcb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0c1b32e5c3e43a999721644d22faa52": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e91b61759b6f4faea42327d5f25240b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f03b199e460947a0ace770d3842decba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f456caf574a640a4b3d4ccf0b3cddd9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f9161803d41147c68a670cc243ad6ef2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
