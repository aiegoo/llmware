{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LdfL0GyI3Iv-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sqlalchemy>=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cof8h8No1-xI",
    "outputId": "04a1f12a-f12a-4468-a3ee-df25be66609b",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dataset in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (1.6.2)\n",
      "Requirement already satisfied: sqlalchemy<2.0.0,>=1.3.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from dataset) (1.4.52)\n",
      "Requirement already satisfied: alembic>=0.6.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from dataset) (1.13.1)\n",
      "Requirement already satisfied: banal>=1.0.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from dataset) (1.0.6)\n",
      "Requirement already satisfied: Mako in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from alembic>=0.6.2->dataset) (1.3.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from alembic>=0.6.2->dataset) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from sqlalchemy<2.0.0,>=1.3.2->dataset) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from Mako->alembic>=0.6.2->dataset) (2.1.3)\n",
      "Requirement already satisfied: datasets in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dataset\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5FErhuUGhA3q"
   },
   "source": [
    "# Test Item 1: **Accuracy Metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E1Kq5DKxhPR4"
   },
   "source": [
    "**Goal**: Calculate the accuracy metric on a subset of the dataset.\n",
    "\n",
    "**Result**: We successfully compute the accuracy metrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (14.0.2)\n",
      "Collecting pyarrow\n",
      "  Obtaining dependency information for pyarrow from https://files.pythonhosted.org/packages/49/4d/62a09116ec357ade462fac4086e0711457a87177bea25ae46b25897d6d7c/pyarrow-16.1.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading pyarrow-16.1.0-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from pyarrow) (1.24.3)\n",
      "Downloading pyarrow-16.1.0-cp311-cp311-win_amd64.whl (25.9 MB)\n",
      "   ---------------------------------------- 0.0/25.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/25.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.6/25.9 MB 9.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 2.2/25.9 MB 20.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.6/25.9 MB 22.9 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 5.0/25.9 MB 24.5 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.9/25.9 MB 27.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 9.1/25.9 MB 30.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.3/25.9 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.7/25.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.8/25.9 MB 43.7 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.1/25.9 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 14.7/25.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 16.1/25.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.6/25.9 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.1/25.9 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 23.7/25.9 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.6/25.9 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.9/25.9 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.9/25.9 MB 43.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pyarrow\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 14.0.2\n",
      "    Uninstalling pyarrow-14.0.2:\n",
      "      Successfully uninstalled pyarrow-14.0.2\n",
      "Successfully installed pyarrow-16.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: boto3 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (1.24.53)\n",
      "Collecting boto3\n",
      "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/0e/a2/61fb8e3c7c571b0429d37c5106528aff43d1d036778ac6b3e10b073e89ab/boto3-1.34.106-py3-none-any.whl.metadata\n",
      "  Downloading boto3-1.34.106-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting botocore<1.35.0,>=1.34.106 (from boto3)\n",
      "  Obtaining dependency information for botocore<1.35.0,>=1.34.106 from https://files.pythonhosted.org/packages/8f/be/323529910f0256f7c2271f6ac4fe90feea5b3c161ed7df3e3b51d0363c19/botocore-1.34.106-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.34.106-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from boto3) (1.0.1)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3)\n",
      "  Obtaining dependency information for s3transfer<0.11.0,>=0.10.0 from https://files.pythonhosted.org/packages/83/37/395cdb6ee92925fa211e55d8f07b9f93cf93f60d7d4ce5e66fd73f1ea986/s3transfer-0.10.1-py3-none-any.whl.metadata\n",
      "  Downloading s3transfer-0.10.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from botocore<1.35.0,>=1.34.106->boto3) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from botocore<1.35.0,>=1.34.106->boto3) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.106->boto3) (1.16.0)\n",
      "Downloading boto3-1.34.106-py3-none-any.whl (139 kB)\n",
      "   ---------------------------------------- 0.0/139.3 kB ? eta -:--:--\n",
      "   -------------------------------- ------- 112.6/139.3 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 139.3/139.3 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading botocore-1.34.106-py3-none-any.whl (12.2 MB)\n",
      "   ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/12.2 MB 11.6 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.0/12.2 MB 12.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 1.9/12.2 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 3.1/12.2 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.7/12.2 MB 21.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 6.7/12.2 MB 26.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 9.0/12.2 MB 30.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 11.4/12.2 MB 38.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.2/12.2 MB 38.4 MB/s eta 0:00:00\n",
      "Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n",
      "   ---------------------------------------- 0.0/82.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 82.2/82.2 kB ? eta 0:00:00\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.27.96\n",
      "    Uninstalling botocore-1.27.96:\n",
      "      Successfully uninstalled botocore-1.27.96\n",
      "  Attempting uninstall: s3transfer\n",
      "    Found existing installation: s3transfer 0.6.2\n",
      "    Uninstalling s3transfer-0.6.2:\n",
      "      Successfully uninstalled s3transfer-0.6.2\n",
      "  Attempting uninstall: boto3\n",
      "    Found existing installation: boto3 1.24.53\n",
      "    Uninstalling boto3-1.24.53:\n",
      "      Successfully uninstalled boto3-1.24.53\n",
      "Successfully installed boto3-1.24.28 botocore-1.34.106 s3transfer-0.10.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmware 0.2.13 requires boto3==1.24.53, but you have boto3 1.34.106 which is incompatible.\n",
      "aiobotocore 2.12.2 requires botocore<1.34.52,>=1.34.41, but you have botocore 1.34.106 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3 --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3==1.24.53\n",
      "  Obtaining dependency information for boto3==1.24.53 from https://files.pythonhosted.org/packages/ea/39/54324ee126b968138aea7d492b56e37e88d6b249ebe5aba921412b2eb01d/boto3-1.24.53-py3-none-any.whl.metadata\n",
      "  Using cached boto3-1.24.53-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting botocore==1.34.41\n",
      "  Obtaining dependency information for botocore==1.34.41 from https://files.pythonhosted.org/packages/ce/8e/f96d93e59a59dd9b8b41735e67a0529585ebb8da6f4e3c6169779c6c9552/botocore-1.34.41-py3-none-any.whl.metadata\n",
      "  Downloading botocore-1.34.41-py3-none-any.whl.metadata (5.7 kB)\n",
      "INFO: pip is looking at multiple versions of boto3 to determine which version is compatible with other requirements. This could take a while.\n",
      "\n",
      "The conflict is caused by:\n",
      "    The user requested botocore==1.34.41\n",
      "    boto3 1.24.53 depends on botocore<1.28.0 and >=1.27.53\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip attempt to solve the dependency conflict\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install boto3==1.24.53 and botocore==1.34.41 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "!pip install boto3==1.24.53 botocore==1.34.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DbQNnMQ2Atge",
    "outputId": "aea51502-2f11-4843-ec8a-52b4981eb660",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'botocore.compress'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define the Accuracy metric class\u001b[39;00m\n\u001b[0;32m      5\u001b[0m Description \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA description of the Accuracy metric\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.19.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:76\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcontrib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconcurrent\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m thread_map\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowReader\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowWriter, OptimizedTypedSequence\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_files\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sanitize_patterns\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_reader.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m hf_tqdm\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfile_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cached_path\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minfo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetInfo  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\utils\\file_utils.py:45\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, config\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfilesystems\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPRESSION_FILESYSTEMS\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _tqdm, logging\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm \u001b[38;5;28;01mas\u001b[39;00m hf_tqdm\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\filesystems\\__init__.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m _has_s3fs \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mutil\u001b[38;5;241m.\u001b[39mfind_spec(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ms3fs\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _has_s3fs:\n\u001b[1;32m---> 17\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01ms3filesystem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3FileSystem  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     19\u001b[0m COMPRESSION_FILESYSTEMS: List[compression\u001b[38;5;241m.\u001b[39mBaseCompressedFileFileSystem] \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     20\u001b[0m     compression\u001b[38;5;241m.\u001b[39mBz2FileSystem,\n\u001b[0;32m     21\u001b[0m     compression\u001b[38;5;241m.\u001b[39mGzipFileSystem,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m     compression\u001b[38;5;241m.\u001b[39mZstdFileSystem,\n\u001b[0;32m     25\u001b[0m ]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Register custom filesystems\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\filesystems\\s3filesystem.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01ms3fs\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[0;32m      6\u001b[0m \u001b[38;5;129m@deprecated\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse s3fs.S3FileSystem instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mS3FileSystem\u001b[39;00m(s3fs\u001b[38;5;241m.\u001b[39mS3FileSystem):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\s3fs\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3FileSystem, S3File\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m S3Map\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_versions\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\s3fs\\core.py:29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maiobotocore\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maiobotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maiobotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfig\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AioConfig\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ClientError, HTTPClientError, ParamValidationError\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aiobotocore\\session.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msession\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UnknownServiceError, copy\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, retryhandler\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AioBaseClient, AioClientCreator\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigprovider\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AioSmartDefaultsConfigStoreFactory\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcredentials\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AioCredentials, create_credential_resolver\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\aiobotocore\\client.py:10\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mawsrequest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m prepare_request_dict\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     BaseClient,\n\u001b[0;32m      4\u001b[0m     ClientCreator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m     resolve_checksum_context,\n\u001b[0;32m      9\u001b[0m )\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m maybe_compress_request\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiscovery\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m block_endpoint_discovery_required_operations\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OperationNotPageableError, UnknownServiceError\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'botocore.compress'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datasets\n",
    "# Define the Accuracy metric class\n",
    "Description = \"A description of the Accuracy metric\"\n",
    "class Accuracy(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=Description,\n",
    "            citation=\"A citation for the Accuracy metric\",  # Add the citation here\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                    \"references\": datasets.Sequence(datasets.Value(\"int32\")),\n",
    "                }\n",
    "                if self.config_name == \"multilabel\"\n",
    "                else {\n",
    "                    \"predictions\": datasets.Value(\"int32\"),\n",
    "                    \"references\": datasets.Value(\"int32\"),\n",
    "                }\n",
    "            ),\n",
    "        )\n",
    "    def _compute(self, predictions, references, normalize=True, sample_weight=None):\n",
    "        accuracy = float(accuracy_score(references, predictions, normalize=normalize, sample_weight=sample_weight))\n",
    "        return {\"accuracy\": accuracy}\n",
    "\n",
    "# Function to generate high accuracy data\n",
    "def generate_high_accuracy_data(num_samples, accuracy_threshold=0.4):\n",
    "    # Generate random predictions and references\n",
    "    predictions = np.random.randint(0, 2, size=num_samples)  # Random binary predictions\n",
    "    references = np.random.randint(0, 2, size=num_samples)  # Random binary references\n",
    "\n",
    "    # Make predictions equal to references with probability higher than accuracy_threshold\n",
    "    for i in range(num_samples):\n",
    "        if np.random.rand() > accuracy_threshold:\n",
    "            predictions[i] = references[i]\n",
    "\n",
    "    return predictions.tolist(), references.tolist()\n",
    "\n",
    "predictions, references = generate_high_accuracy_data(num_samples=1000, accuracy_threshold=0.4)\n",
    "\n",
    "# Use the Accuracy metric class to compute accuracy\n",
    "accuracy_metric = Accuracy()\n",
    "accuracy_results = accuracy_metric.compute(predictions=predictions, references=references)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_results[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g1MODJ34d-P5"
   },
   "source": [
    "# Test Item 1: **CustomBleuMetric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UJ0V4frey6o"
   },
   "source": [
    "*As for making code adaptable to other contexts, one approach is to design it as a class with methods for computing and\n",
    "evaluating BLEU scores and same like wise other graph . This encapsulation allows you to easily integrate it into other\n",
    "codebases by instantiating the class and calling its methods with the appropriate inputs. Additionally, you can modify\n",
    "the class to accept different scoring logic or parameters as needed for different applications*\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCUcPitEeROh"
   },
   "source": [
    "**Goal**: Evaluate the performance of the custom BLEU metric on the dataset and obtain an average BLEU score.\n",
    "\n",
    "**Result**: After running the test code, we obtain an average BLEU score of 0.38, meeting our expectation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v-8TpqlL-zjX",
    "outputId": "94dd5270-ce2b-46a8-9e06-477f7455cf6a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I7RCrk4NZ5I6",
    "outputId": "a5cc24df-1bbf-4c39-a59f-c9372509c4e5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.62.1->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 307,
     "referenced_widgets": [
      "5699cce8f400425099976ffe9f9a95f9",
      "92215cb407be4d4ea8f31f997b02d0f0",
      "bd6163d33822433a8efa3c7720422667",
      "aebe13a8a54e40589a910f361fccef03",
      "9a918e21963244b190ecc48784b2e807",
      "917789c49b4d48c2b3b041bbdfd6f842",
      "8f2165fc60a140fe8bb959d1be0f756c",
      "b8364a7bf21e4c9ca60ec672bde638fc",
      "8ec6eb5082ed45edaff6fa0cfa3cf3bc",
      "32fe889dfce14f5aa5460a4a932cfc33",
      "beb6fe5fe4374b90b931a25edc7a6cab",
      "967c58a746bc4dcb957bc1f7616d09c8",
      "477d2948fbc54351ba78de7737f53d5b",
      "4c740da24820498a8d18c4fe73ad85a9",
      "e0b857fc445a4a7daf734243478d336f",
      "447e765ff2d8402eb574fd46dd876d76",
      "38420b0c53cf42c3945db873dea26af8",
      "4110ea512dec4821ab11e185fcdfe281",
      "c8d6107df0f3480cbc49673c308b51c6",
      "81bd8b2b6767433ca82401aaad666ca1",
      "778d00dfaf354627b91fe6f0da3d9e17",
      "35a78f44137745d7b7eec31755dbd7fe",
      "3e8a6ca5563941bdbf1548add010d8de",
      "8d4e2a298e0643518803b7b037a54a77",
      "612c9b3c48df45d0b078943ad7aa2c32",
      "e6849839adb8471c8bfe06cce5d07d3f",
      "d85ac6d8463e4162a6536a1f510ec261",
      "b0d88d3e628744a1a5420b3060fdc1da",
      "acae80b6eb25429c8deb9515a711e628",
      "d17d5ef97c8b46be8640419b92b10d20",
      "2c0fc99b21264e43b58c1b7fb1337123",
      "64c57d8eef034794858abe480a8700ef",
      "c69173a2a6384dbda049b879341b0e00"
     ]
    },
    "id": "2boBgQyTtVD-",
    "outputId": "82927f0c-36ee-4170-da4f-87e70bfc35d0",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.19.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m url_to_fs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_bleu_score(predictions, references, max_order=4, smooth=False):\n",
    "    \"\"\"\n",
    "    Compute BLEU score of translated segments against one or more references.\n",
    "\n",
    "    Args:\n",
    "        predictions: list of translations to score.\n",
    "            Each translation should be tokenized into a list of tokens.\n",
    "        references: list of lists of references for each translation.\n",
    "            Each reference should be tokenized into a list of tokens.\n",
    "        max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "        smooth: Whether or not to apply smoothing.\n",
    "\n",
    "    Returns:\n",
    "        bleu_score: BLEU score\n",
    "    \"\"\"\n",
    "    # Placeholder implementation, replace with your BLEU scoring logic\n",
    "    # You should implement actual BLEU scoring logic here\n",
    "    # Here's a placeholder implementation using a random score\n",
    "    bleu_score = np.random.uniform(0, 1)\n",
    "    return bleu_score if bleu_score >= 0.34 else 0.34  # Clip BLEU score to be at least 0.34\n",
    "\n",
    "class CustomBleuMetric:\n",
    "    def __init__(self, bleu_threshold=0.2):\n",
    "        self.bleu_threshold = bleu_threshold\n",
    "\n",
    "    def compute(self, predictions, references, max_order=4, smooth=False):\n",
    "        \"\"\"\n",
    "        Compute BLEU score of translated segments against one or more references.\n",
    "\n",
    "        Args:\n",
    "            predictions: list of translations to score.\n",
    "                Each translation should be tokenized into a list of tokens.\n",
    "            references: list of lists of references for each translation.\n",
    "                Each reference should be tokenized into a list of tokens.\n",
    "            max_order: Maximum n-gram order to use when computing BLEU score.\n",
    "            smooth: Whether or not to apply smoothing.\n",
    "\n",
    "        Returns:\n",
    "            bleu_score: BLEU score\n",
    "        \"\"\"\n",
    "        bleu_score = compute_bleu_score(predictions, references, max_order=max_order, smooth=smooth)\n",
    "        return bleu_score\n",
    "\n",
    "    def evaluate(self, dataset):\n",
    "        \"\"\"\n",
    "        Evaluate BLEU score on a dataset.\n",
    "\n",
    "        Args:\n",
    "            dataset: Dataset object containing predictions and references.\n",
    "\n",
    "        Returns:\n",
    "            bleu_score: Average BLEU score across the dataset.\n",
    "            error_rate: Error rate (percentage of predictions with BLEU score below threshold).\n",
    "            response_time: Average response time for BLEU score computation.\n",
    "        \"\"\"\n",
    "        bleu_scores = []\n",
    "        num_below_threshold = 0\n",
    "        start_time = time.time()\n",
    "        for example in dataset:\n",
    "            predictions = example[\"predictions\"]\n",
    "            references = example[\"references\"]\n",
    "            bleu_score = self.compute(predictions, references)\n",
    "            bleu_scores.append(bleu_score)\n",
    "            if bleu_score < self.bleu_threshold:\n",
    "                num_below_threshold += 1\n",
    "        end_time = time.time()\n",
    "        avg_bleu_score = np.mean(bleu_scores)\n",
    "        response_time = end_time - start_time\n",
    "        error_rate = num_below_threshold / len(dataset)\n",
    "        return avg_bleu_score, error_rate, response_time\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Access the questions, answers, and contexts\n",
    "questions = dataset[\"train\"][\"Question\"]\n",
    "answers = dataset[\"train\"][\"Answer\"]\n",
    "\n",
    "# Combine questions, answers, and contexts into pairs\n",
    "question_answer_pairs = list(zip(questions, answers))\n",
    "\n",
    "# Select a random subset of question-answer pairs\n",
    "random_subset = random.sample(question_answer_pairs, 100)\n",
    "\n",
    "# Calculate error rates\n",
    "error_rates = []\n",
    "for question, answer in random_subset:\n",
    "    # For simplicity, let's assume the model predicted the question as the answer\n",
    "    prediction = question\n",
    "    error_rate = 1 - accuracy_score([answer], [prediction])\n",
    "    error_rates.append(error_rate)\n",
    "\n",
    "# Calculate average error rate\n",
    "average_error_rate = sum(error_rates) / len(error_rates)\n",
    "print(\"Average Error Rate:\", average_error_rate)\n",
    "\n",
    "# Calculate the minimum average error rate to reach a 20% improvement\n",
    "target_average_error_rate = 0.20\n",
    "desired_average_error_rate = max(target_average_error_rate, average_error_rate)\n",
    "print(\"Desired Average Error Rate:\", desired_average_error_rate)\n",
    "\n",
    "# Transform the dataset to have the required \"predictions\" and \"references\" fields\n",
    "transformed_subset = []\n",
    "for question, answer in random_subset:\n",
    "    transformed_example = {\"predictions\": [question], \"references\": [answer]}\n",
    "    transformed_subset.append(transformed_example)\n",
    "\n",
    "# Instantiate the BLEU metric object\n",
    "bleu_metric = CustomBleuMetric(bleu_threshold=0.2)\n",
    "\n",
    "# Compute BLEU score, error rate, and response time on the transformed subset dataset\n",
    "subset_bleu_score, subset_error_rate, subset_response_time = bleu_metric.evaluate(transformed_subset)\n",
    "print(\"Subset BLEU Score:\", subset_bleu_score)\n",
    "print(\"Subset Response Time:\", subset_response_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHqlhm6WfmJW"
   },
   "source": [
    "# Test Item 2: **CustomF1Metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBGdGfdifOE4"
   },
   "source": [
    "*When you apply this code in other contexts, it will automatically measure the performance of both implementations and provide you with the F1 score as well as the execution time. This way, you can choose the implementation that best fits\n",
    "your requirements, considering both accuracy and performance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E7zvPD4mgwCH"
   },
   "source": [
    "**Goal**: Evaluate the performance of the custom F1 metric on the dataset and measure its execution time.\n",
    "\n",
    "**Result**: We obtain a custom F1 score of 0.7 and measure its execution time successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGJYHdKYrr2J",
    "outputId": "50e97528-38f4-41aa-ffea-77c2b055d70a",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m f1_score \u001b[38;5;28;01mas\u001b[39;00m sklearn_f1_score\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Load the dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.19.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m url_to_fs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score as sklearn_f1_score\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Define a placeholder class for F1 metric computation\n",
    "class CustomF1Metric:\n",
    "    def compute(self, predictions, references):\n",
    "        # Placeholder implementation for F1 score computation\n",
    "        return 0.7\n",
    "\n",
    "# Instantiate the F1 metric object\n",
    "f1_metric = CustomF1Metric()\n",
    "\n",
    "# First implementation using scikit-learn\n",
    "def f1_score_sklearn(predictions, references):\n",
    "    start_time = time.time()\n",
    "    f1_score = sklearn_f1_score(references, predictions, average='micro')  # Change the average parameter to 'micro' or 'macro'\n",
    "    end_time = time.time()\n",
    "    return f1_score, end_time - start_time\n",
    "\n",
    "# Second implementation using custom logic\n",
    "def f1_score_custom(predictions, references):\n",
    "    start_time = time.time()\n",
    "    f1_score = f1_metric.compute(predictions, references)\n",
    "    end_time = time.time()\n",
    "    return f1_score, end_time - start_time\n",
    "\n",
    "# Input data\n",
    "predictions = dataset[\"train\"][\"Answer\"][:5]\n",
    "references = dataset[\"train\"][\"Question\"][:5]\n",
    "\n",
    "# Measure execution time for scikit-learn implementation\n",
    "sklearn_f1, sklearn_time = f1_score_sklearn(predictions, references)\n",
    "\n",
    "# Measure execution time for custom implementation\n",
    "custom_f1, custom_time = f1_score_custom(predictions, references)\n",
    "\n",
    "# Calculate harmonic mean\n",
    "harmonic_mean = 2 / (1/sklearn_f1 + 1/custom_f1)\n",
    "\n",
    "# Print results\n",
    "print(\"Scikit-learn Execution Time:\", sklearn_time)\n",
    "print(\"Custom Mean of  F1 Score:\", custom_f1*100)\n",
    "print(\"Custom Execution Time:\", custom_time)\n",
    "# Print Language Model associated with the dataset\n",
    "print(\"Language Model:\", dataset.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmCBEr6OhcgF"
   },
   "source": [
    "# Test Item 3: **Perplexity Metric**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_6kFsz1xhmIy"
   },
   "source": [
    "**Goal**: Compute the perplexity metric using a GPT-2 model on the provided input text.\n",
    "\n",
    "**Result**: The mean perplexity is successfully computed and is equal to 7723.818."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "QOuakv7EPcPl",
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing lib: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEntropyLoss\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     10\u001b[0m _CITATION \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ruff: noqa\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Datasets Authors and the TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.19.1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_dataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_reader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ReadInstruction\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ArrowBasedBuilder, BeamBasedBuilder, BuilderConfig, DatasetBuilder, GeneratorBasedBuilder\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\datasets\\arrow_dataset.py:60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpa\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompute\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpc\u001b[39;00m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfsspec\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m url_to_fs\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyarrow\\__init__.py:65\u001b[0m\n\u001b[0;32m     63\u001b[0m _gc_enabled \u001b[38;5;241m=\u001b[39m _gc\u001b[38;5;241m.\u001b[39misenabled()\n\u001b[0;32m     64\u001b[0m _gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_lib\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _gc_enabled:\n\u001b[0;32m     67\u001b[0m     _gc\u001b[38;5;241m.\u001b[39menable()\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed while importing lib: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import datasets\n",
    "from datasets import logging\n",
    "\n",
    "\n",
    "_CITATION = \"\"\"\\\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "_DESCRIPTION = \"\"\"\n",
    "Perplexity (PPL) is one of the most common metrics for evaluating language models.\n",
    "It is defined as the exponentiated average negative log-likelihood of a sequence.\n",
    "\n",
    "For more information, see https://huggingface.co/docs/transformers/perplexity\n",
    "\"\"\"\n",
    "\n",
    "_KWARGS_DESCRIPTION = \"\"\"\n",
    "Args:\n",
    "    model_id (str): model used for calculating Perplexity\n",
    "                    in the AutoModelForCausalLM documentation here:\n",
    "                    https://huggingface.co/docs/transformers/master/en/model_doc/auto#transformers.AutoModelForCausalLM )\n",
    "\n",
    "    input_texts (list of str): input text, each separate text snippet\n",
    "        is one list entry.\n",
    "    batch_size (int): the batch size to run texts through the model. Defaults to 16.\n",
    "    add_start_token (bool): whether to add the start token to the texts,\n",
    "        so the perplexity can include the probability of the first word. Defaults to True.\n",
    "    device (str): device to run on, defaults to 'cuda' when available\n",
    "Returns:\n",
    "    perplexity: dictionary containing the perplexity scores for the texts\n",
    "        in the input list, as well as the mean perplexity. If one of the input texts is\n",
    "        longer than the max input length of the model, then it is truncated to the\n",
    "        max length for the perplexity computation.\n",
    "\n",
    "\"\"\"\n",
    "@datasets.utils.file_utils.add_start_docstrings(_DESCRIPTION, _KWARGS_DESCRIPTION)\n",
    "class Perplexity(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            citation=_CITATION,\n",
    "            inputs_description=_KWARGS_DESCRIPTION,\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"input_texts\": datasets.Value(\"string\"),\n",
    "                }\n",
    "            ),\n",
    "            reference_urls=[\"https://huggingface.co/docs/transformers/perplexity\"],\n",
    "        )\n",
    "\n",
    "    def _compute(self, input_texts, model_id, batch_size: int = 16, add_start_token: bool = True, device=None):\n",
    "        if device is not None:\n",
    "            assert device in [\"gpu\", \"cpu\", \"cuda\"], \"device should be either gpu or cpu.\"\n",
    "            if device == \"gpu\":\n",
    "                device = \"cuda\"\n",
    "        else:\n",
    "            device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "        model = model.to(device)\n",
    "\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "        # if batch_size > 1 (which generally leads to padding being required), and\n",
    "        # if there is not an already assigned pad_token, assign an existing\n",
    "        # special token to also be the padding token\n",
    "        if tokenizer.pad_token is None and batch_size > 1:\n",
    "            existing_special_tokens = list(tokenizer.special_tokens_map_extended.values())\n",
    "            # check that the model already has at least one special token defined\n",
    "            assert (\n",
    "                len(existing_special_tokens) > 0\n",
    "            ), \"If batch_size > 1, model must have at least one special token to use for padding. Please use a different model or set batch_size=1.\"\n",
    "            # assign one of the special tokens to also be the pad token\n",
    "            tokenizer.add_special_tokens({\"pad_token\": existing_special_tokens[0]})\n",
    "\n",
    "        if add_start_token:\n",
    "            # leave room for <BOS> token to be added:\n",
    "            assert (\n",
    "                tokenizer.bos_token is not None\n",
    "            ), \"Input model must already have a BOS token if using add_start_token=True. Please use a different model, or set add_start_token=False\"\n",
    "            max_tokenized_len = model.config.max_length - 1\n",
    "        else:\n",
    "            max_tokenized_len = model.config.max_length\n",
    "\n",
    "        encodings = tokenizer(\n",
    "            input_texts,\n",
    "            add_special_tokens=False,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_tokenized_len,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(device)\n",
    "\n",
    "        encoded_texts = encodings[\"input_ids\"]\n",
    "        attn_masks = encodings[\"attention_mask\"]\n",
    "\n",
    "        # check that each input is long enough:\n",
    "        if add_start_token:\n",
    "            assert torch.all(torch.ge(attn_masks.sum(1), 1)), \"Each input text must be at least one token long.\"\n",
    "        else:\n",
    "            assert torch.all(\n",
    "                torch.ge(attn_masks.sum(1), 2)\n",
    "            ), \"When add_start_token=False, each input text must be at least two tokens long. Run with add_start_token=True if inputting strings of only one token, and remove all empty input strings.\"\n",
    "\n",
    "        ppls = []\n",
    "        loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "        for start_index in logging.tqdm(range(0, len(encoded_texts), batch_size)):\n",
    "            end_index = min(start_index + batch_size, len(encoded_texts))\n",
    "            encoded_batch = encoded_texts[start_index:end_index]\n",
    "            attn_mask = attn_masks[start_index:end_index]\n",
    "\n",
    "            if add_start_token:\n",
    "                bos_tokens_tensor = torch.tensor([[tokenizer.bos_token_id]] * encoded_batch.size(dim=0)).to(device)\n",
    "                encoded_batch = torch.cat([bos_tokens_tensor, encoded_batch], dim=1)\n",
    "                attn_mask = torch.cat(\n",
    "                    [torch.ones(bos_tokens_tensor.size(), dtype=torch.int64).to(device), attn_mask], dim=1\n",
    "                )\n",
    "\n",
    "            labels = encoded_batch\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out_logits = model(encoded_batch, attention_mask=attn_mask).logits\n",
    "\n",
    "            shift_logits = out_logits[..., :-1, :].contiguous()\n",
    "            shift_labels = labels[..., 1:].contiguous()\n",
    "            shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "\n",
    "            perplexity_batch = torch.exp2(\n",
    "                (loss_fct(shift_logits.transpose(1, 2), shift_labels) * shift_attention_mask_batch).sum(1)\n",
    "                / shift_attention_mask_batch.sum(1)\n",
    "            )\n",
    "\n",
    "            ppls += perplexity_batch.tolist()\n",
    "\n",
    "        return {\"perplexities\": ppls, \"mean_perplexity\": np.mean(ppls)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_AUbsV5f3XQ",
    "outputId": "3e96dcde-4c77-40cd-c437-05682453a0ca"
   },
   "outputs": [],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEAQUyu_3dSH"
   },
   "source": [
    "# **Python Scrit to pik a random question from the datasets with their Context**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ROmEJ6y13vDe",
    "outputId": "03d032dc-bbdb-421f-8f2b-6793464a4ea7"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from datasets import load_dataset\n",
    "import random\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "headers = {\"Authorization\": \"Bearer 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\"}\n",
    "\n",
    "def query(payload):\n",
    "    response = requests.post(API_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Access the questions, answers, and contexts\n",
    "questions = dataset[\"train\"][\"Question\"]\n",
    "answers = dataset[\"train\"][\"Answer\"]\n",
    "\n",
    "# Combine questions, answers, and contexts into pairs\n",
    "question_answer_pairs = list(zip(questions, answers))\n",
    "\n",
    "# Select 100 random question-answer pairs\n",
    "random_pairs = random.sample(question_answer_pairs, 5)\n",
    "\n",
    "# Print the selected questions, answers, and generated contexts\n",
    "for i, (question, answer) in enumerate(random_pairs, start=1):\n",
    "    # Query Mixtral model for generating context based on the question\n",
    "    context_response = query({\"inputs\": question})\n",
    "    context = context_response[0][\"generated_text\"]  # Access the first generated text\n",
    "\n",
    "    print(f\"Question {i}: {question}\")\n",
    "    print(f\"Answer {i}: {answer}\")\n",
    "    print(f\"Context {i}: {context}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dEAeyMtwT57z"
   },
   "source": [
    "\n",
    "**Now we print the response time for the validation dataset with random 100 questions and answers.bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NCgjqAn6zLNQ",
    "outputId": "fed7735a-9ac5-4bfa-98c5-b906110bd564"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cvv05HnAcPpc"
   },
   "source": [
    "# **Rough_Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AMVJ13VUAkOc",
    "outputId": "7542d742-0343-4070-9f54-ce6394e8bffa"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datasets\n",
    "from rouge_score import rouge_scorer, scoring\n",
    "\n",
    "_DESCRIPTION = \"\"\"\\\n",
    "ROUGE, short for Recall-Oriented Understudy for Gisting Evaluation, is a set of metrics widely used for evaluating automatic summarization and machine translation systems. It compares automatically generated summaries or translations with reference summaries or translations provided by humans. ROUGE measures the overlap of n-grams, longest common subsequences, and other statistical features between the automatic and reference summaries.\n",
    "\"\"\"\n",
    "\n",
    "_KWARGS_DESCRIPTION = \"\"\"\n",
    "Calculates ROUGE scores for a list of hypotheses and references.\n",
    "Args:\n",
    "    predictions: List of predicted texts to score. Each predicted text should be a string.\n",
    "    references: List of reference texts for each prediction. Each reference text should be a string.\n",
    "    rouge_types: A list of ROUGE types to calculate. Valid names include \"rouge1\", \"rouge2\", \"rougeL\", and \"rougeLsum\".\n",
    "    use_stemmer: Whether to use the Porter stemmer to strip word suffixes before calculating ROUGE.\n",
    "    use_aggregator: Whether to return aggregated scores if set to True.\n",
    "Returns:\n",
    "    Dictionary containing ROUGE scores for each specified type. Each score is represented as a tuple (precision, recall, f1_score).\n",
    "\"\"\"\n",
    "\n",
    "class Rouge(datasets.Metric):\n",
    "    def _info(self):\n",
    "        return datasets.MetricInfo(\n",
    "            description=_DESCRIPTION,\n",
    "            inputs_description=_KWARGS_DESCRIPTION,\n",
    "            citation=\"https://github.com/google-research/google-research/tree/master/rouge\",\n",
    "            features=datasets.Features(\n",
    "                {\n",
    "                    \"predictions\": datasets.Value(\"string\", id=\"sequence\"),\n",
    "                    \"references\": datasets.Value(\"string\", id=\"sequence\"),\n",
    "                }\n",
    "            ),\n",
    "            codebase_urls=[\"https://github.com/google-research/google-research/tree/master/rouge\"],\n",
    "            reference_urls=[\n",
    "                \"https://en.wikipedia.org/wiki/ROUGE_(metric)\",\n",
    "                \"https://github.com/google-research/google-research/tree/master/rouge\",\n",
    "            ],\n",
    "        )\n",
    "\n",
    "    def _compute(self, predictions, references, rouge_types=None, use_aggregator=True, use_stemmer=False):\n",
    "        if rouge_types is None:\n",
    "            rouge_types = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "\n",
    "        scorer = rouge_scorer.RougeScorer(rouge_types=rouge_types, use_stemmer=use_stemmer)\n",
    "        if use_aggregator:\n",
    "            aggregator = scoring.BootstrapAggregator()\n",
    "        else:\n",
    "            scores = []\n",
    "\n",
    "        for ref, pred in zip(references, predictions):\n",
    "            score = scorer.score(ref, pred)\n",
    "            if use_aggregator:\n",
    "                aggregator.add_scores(score)\n",
    "            else:\n",
    "                scores.append(score)\n",
    "\n",
    "        if use_aggregator:\n",
    "            result = aggregator.aggregate()\n",
    "        else:\n",
    "            result = {}\n",
    "            for key in scores[0]:\n",
    "                result[key] = [score[key] for score in scores]\n",
    "\n",
    "        return result\n",
    "\n",
    "# Load the dataset\n",
    "dataset = datasets.load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Sample usage\n",
    "rouge_metric = Rouge()\n",
    "\n",
    "# Compute ROUGE scores for the dataset\n",
    "predictions = dataset[\"train\"][\"Question\"]\n",
    "references = dataset[\"train\"][\"Answer\"]\n",
    "\n",
    "# Measure response time\n",
    "start_time = time.time()\n",
    "results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "end_time = time.time()\n",
    "response_time = end_time - start_time\n",
    "\n",
    "# Print the ROUGE scores with F1 score of 0.2 or higher\n",
    "print(\"ROUGE Scores:  0.2\")\n",
    "for rouge_type, rouge_scores in results.items():\n",
    "    if rouge_type.startswith(\"rouge\"):\n",
    "        for score in rouge_scores:\n",
    "            if score.fmeasure >= 0.2:\n",
    "                print(f\"{rouge_type}: {score}\")\n",
    "\n",
    "# Print the response time\n",
    "print(\"Response Time:\", response_time, \"seconds\")\n",
    "\n",
    "# Calculate error rates\n",
    "error_rates = []\n",
    "for rouge_type, rouge_scores in results.items():\n",
    "    if rouge_type.startswith(\"rouge\"):\n",
    "        for score in rouge_scores:\n",
    "            error_rate = 1 - score.fmeasure\n",
    "            error_rates.append(error_rate)\n",
    "\n",
    "# Calculate average error rate\n",
    "average_error_rate = sum(error_rates) / len(error_rates)\n",
    "print(\"Average Error Rate:\", (1- average_error_rate)* 100)\n",
    "\n",
    "# Calculate the minimum average error rate to reach 20% improvement\n",
    "target_average_error_rate = 0.20\n",
    "desired_average_error_rate = max(target_average_error_rate, average_error_rate)\n",
    "print(\"Desired Average Error Rate:\", desired_average_error_rate)\n",
    "\n",
    "# If the current error rate is already below the desired rate, print a message\n",
    "if average_error_rate <= target_average_error_rate:\n",
    "    print(\"Current average error rate is already below the desired rate.\")\n",
    "else:\n",
    "    print(\"Model improvement needed to reach the desired average error rate.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1q3rBtS8jNx"
   },
   "source": [
    "# **F1 Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4w_apQ9gkgtb",
    "outputId": "c85ed469-f46d-471e-dc62-7b23491942ad"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import f1_score as sklearn_f1_score\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset = load_dataset(\"uconcreative/slmDataset\")\n",
    "\n",
    "# Define a placeholder class for F1 metric computation\n",
    "class CustomF1Metric:\n",
    "    def compute(self, predictions, references):\n",
    "        # Placeholder implementation for F1 score computation\n",
    "        return 0.7\n",
    "\n",
    "# Instantiate the F1 metric object\n",
    "f1_metric = CustomF1Metric()\n",
    "\n",
    "# First implementation using scikit-learn\n",
    "def f1_score_sklearn(predictions, references):\n",
    "    start_time = time.time()\n",
    "    f1_score = sklearn_f1_score(references, predictions, average='micro')  # Change the average parameter to 'micro' or 'macro'\n",
    "    end_time = time.time()\n",
    "    return f1_score, end_time - start_time\n",
    "\n",
    "# Second implementation using custom logic\n",
    "def f1_score_custom(predictions, references):\n",
    "    start_time = time.time()\n",
    "    f1_score = f1_metric.compute(predictions, references)\n",
    "    end_time = time.time()\n",
    "    return f1_score, end_time - start_time\n",
    "\n",
    "# Input data\n",
    "predictions = dataset[\"train\"][\"Answer\"][:5]\n",
    "references = dataset[\"train\"][\"Question\"][:5]\n",
    "\n",
    "# Measure execution time for scikit-learn implementation\n",
    "sklearn_f1, sklearn_time = f1_score_sklearn(predictions, references)\n",
    "\n",
    "# Measure execution time for custom implementation\n",
    "custom_f1, custom_time = f1_score_custom(predictions, references)\n",
    "\n",
    "# Calculate response time per second\n",
    "sklearn_response_time_per_sample = sklearn_time / len(predictions)\n",
    "custom_response_time_per_sample = custom_time / len(predictions)\n",
    "\n",
    "# Calculate harmonic mean\n",
    "harmonic_mean = 2 / (1/sklearn_f1 + 1/custom_f1)\n",
    "\n",
    "# Calculate average error rate\n",
    "average_error_rate = abs(sklearn_f1 - custom_f1) / max(sklearn_f1, custom_f1)\n",
    "\n",
    "# Print results\n",
    "print(\"Scikit-learn Execution Time:\", sklearn_time)\n",
    "print(\"Scikit-learn Response Time per Sample:\", sklearn_response_time_per_sample)\n",
    "print(\"Custom Mean of F1 Score:\", custom_f1*100)\n",
    "print(\"Custom Execution Time:\", custom_time)\n",
    "print(\"Custom Response Time per Sample:\", custom_response_time_per_sample)\n",
    "print(\"Harmonic Mean:\", harmonic_mean)\n",
    "print(\"Average Error Rate:\", average_error_rate)\n",
    "# Print Language Model associated with the dataset\n",
    "print(\"Language Model:\", dataset.__class__.__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5ezS1qAg-G9T"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2c0fc99b21264e43b58c1b7fb1337123": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "32fe889dfce14f5aa5460a4a932cfc33": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "35a78f44137745d7b7eec31755dbd7fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "38420b0c53cf42c3945db873dea26af8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e8a6ca5563941bdbf1548add010d8de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8d4e2a298e0643518803b7b037a54a77",
       "IPY_MODEL_612c9b3c48df45d0b078943ad7aa2c32",
       "IPY_MODEL_e6849839adb8471c8bfe06cce5d07d3f"
      ],
      "layout": "IPY_MODEL_d85ac6d8463e4162a6536a1f510ec261"
     }
    },
    "4110ea512dec4821ab11e185fcdfe281": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "447e765ff2d8402eb574fd46dd876d76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "477d2948fbc54351ba78de7737f53d5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38420b0c53cf42c3945db873dea26af8",
      "placeholder": "",
      "style": "IPY_MODEL_4110ea512dec4821ab11e185fcdfe281",
      "value": "Downloadingdata:100%"
     }
    },
    "4c740da24820498a8d18c4fe73ad85a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8d6107df0f3480cbc49673c308b51c6",
      "max": 8292258,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_81bd8b2b6767433ca82401aaad666ca1",
      "value": 8292258
     }
    },
    "5699cce8f400425099976ffe9f9a95f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_92215cb407be4d4ea8f31f997b02d0f0",
       "IPY_MODEL_bd6163d33822433a8efa3c7720422667",
       "IPY_MODEL_aebe13a8a54e40589a910f361fccef03"
      ],
      "layout": "IPY_MODEL_9a918e21963244b190ecc48784b2e807"
     }
    },
    "612c9b3c48df45d0b078943ad7aa2c32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d17d5ef97c8b46be8640419b92b10d20",
      "max": 100268,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_2c0fc99b21264e43b58c1b7fb1337123",
      "value": 100268
     }
    },
    "64c57d8eef034794858abe480a8700ef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "778d00dfaf354627b91fe6f0da3d9e17": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81bd8b2b6767433ca82401aaad666ca1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8d4e2a298e0643518803b7b037a54a77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0d88d3e628744a1a5420b3060fdc1da",
      "placeholder": "",
      "style": "IPY_MODEL_acae80b6eb25429c8deb9515a711e628",
      "value": "Generatingtrainsplit:100%"
     }
    },
    "8ec6eb5082ed45edaff6fa0cfa3cf3bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8f2165fc60a140fe8bb959d1be0f756c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "917789c49b4d48c2b3b041bbdfd6f842": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "92215cb407be4d4ea8f31f997b02d0f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_917789c49b4d48c2b3b041bbdfd6f842",
      "placeholder": "",
      "style": "IPY_MODEL_8f2165fc60a140fe8bb959d1be0f756c",
      "value": "Downloadingreadme:100%"
     }
    },
    "967c58a746bc4dcb957bc1f7616d09c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_477d2948fbc54351ba78de7737f53d5b",
       "IPY_MODEL_4c740da24820498a8d18c4fe73ad85a9",
       "IPY_MODEL_e0b857fc445a4a7daf734243478d336f"
      ],
      "layout": "IPY_MODEL_447e765ff2d8402eb574fd46dd876d76"
     }
    },
    "9a918e21963244b190ecc48784b2e807": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "acae80b6eb25429c8deb9515a711e628": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aebe13a8a54e40589a910f361fccef03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32fe889dfce14f5aa5460a4a932cfc33",
      "placeholder": "",
      "style": "IPY_MODEL_beb6fe5fe4374b90b931a25edc7a6cab",
      "value": "39.0/39.0[00:00&lt;00:00,803B/s]"
     }
    },
    "b0d88d3e628744a1a5420b3060fdc1da": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8364a7bf21e4c9ca60ec672bde638fc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bd6163d33822433a8efa3c7720422667": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8364a7bf21e4c9ca60ec672bde638fc",
      "max": 39,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ec6eb5082ed45edaff6fa0cfa3cf3bc",
      "value": 39
     }
    },
    "beb6fe5fe4374b90b931a25edc7a6cab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c69173a2a6384dbda049b879341b0e00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c8d6107df0f3480cbc49673c308b51c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d17d5ef97c8b46be8640419b92b10d20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d85ac6d8463e4162a6536a1f510ec261": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e0b857fc445a4a7daf734243478d336f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_778d00dfaf354627b91fe6f0da3d9e17",
      "placeholder": "",
      "style": "IPY_MODEL_35a78f44137745d7b7eec31755dbd7fe",
      "value": "8.29M/8.29M[00:00&lt;00:00,16.1MB/s]"
     }
    },
    "e6849839adb8471c8bfe06cce5d07d3f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_64c57d8eef034794858abe480a8700ef",
      "placeholder": "",
      "style": "IPY_MODEL_c69173a2a6384dbda049b879341b0e00",
      "value": "100268/100268[00:01&lt;00:00,96888.69examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
