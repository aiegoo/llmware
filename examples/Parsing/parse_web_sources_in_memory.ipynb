{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " This example demonstrates how to parse various web sources into a Library through HTML scraping.<br>\n",
    "    When parsing websites, please follow best practices, ethical guidelines and common sense - as a good example,<br>\n",
    "    see https://monashdatafluency.github.io/python-web-scraping/section-5-legal-and-ethical-considerations/<br>\n",
    "    To use the WebSite Parser requires several additional python libraries to be installed:<br>\n",
    "        pip3 install beautifulsoup4<br>\n",
    "        pip3 install lxml<br>\n",
    "        pip3 install requests<br>\n",
    "        pip3 install urllib3<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmware.parsers import Parser, WebSiteParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsing_web_sources_in_memory():\n",
    "    \"\"\" In this example. we will access the WebSiteParser through the general Parser class, with the main use\n",
    "    case of integrating a small HTML site into a library with inclusion of other file types.\n",
    "    We recommend checking the website output first in memory, before automatically adding to a DB - as\n",
    "    usually the extracted text will require some post-processing to remove redundancies, potential formatting or JS -\n",
    "    and as a general safety check on the content. \"\"\"\n",
    "    print(f\"\\nExample - Parsing Web Sources\")\n",
    "\n",
    "    #   parse website directly - here are a few ideas for rapid testing\n",
    "    #   please be respectful in keeping requests at low volume\n",
    "\n",
    "    #   high volume global website\n",
    "    website = \"https://www.cnbc.com\"\n",
    "\n",
    "    #   come visit NYC\n",
    "    website = \"https://www.ny.com/general/centers.html\"\n",
    "    # website = \"https://bronxzoo.com\"\n",
    "    # website = \"https://en.wikipedia.org/wiki/Jalen_Brunson\"\n",
    "    website_parsed_output = Parser().parse_website(website, write_to_db=False, save_history=False, get_links=False)\n",
    "\n",
    "    # look at the first 10 text blocks extracted\n",
    "    for x in range(0,min(10, len(website_parsed_output))):\n",
    "        print(\"text blocks extracted: \", website_parsed_output[x])\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parsing_web_sources_in_memory()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
