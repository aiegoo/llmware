{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Example:   ** Applying OCR to Images in LLMWare Library **<br>\n",
    "    This example shows how to:<br>\n",
    "    A.  identify images in a library (post the initial parsing)<br>\n",
    "    B.  run an OCR against the images to derive the text from the image using the OCR<br>\n",
    "    C.  insert the text into the database library collection for subsequent retrieval.<br>\n",
    "    Note: this example uses additional python dependencies:<br>\n",
    "        -- pip3 install pytesseract<br>\n",
    "    Note: this example uses an OCR engine, which is outside of the core llmware package.  To install on Ubuntu:<br>\n",
    "        -- sudo apt install tesseract-ocr<br>\n",
    "        -- sudo apt install libtesseract-dev<br>\n",
    "    [Other platforms:<br>\n",
    "        -- Mac: brew install tesseract<br>\n",
    "        -- Windows:   GUI download installer - see UB-Mannheim @ www.github.com/UB-Mannheim/tesseract/wiki<br>\n",
    "    Running this script will NOT make any changes to the original \"image\" block record in the text collection.<br>\n",
    "    Rather than update/replace the existing record, the script will create a new supplemental entry for each 'image'.<br>\n",
    "    Each new record will have the following attributes:<br>\n",
    "        --\"text\" block with the text derived from the OCR, including the original source doc_ID, file source name and<br>\n",
    "        page number for easy reference<br>\n",
    "        --new block_ID starting at 100000 (safely out of the 'block namespace' of the original document, and easy to<br>\n",
    "            identify as 'derived' text from an OCR, rather than an original part of the document<br>\n",
    "        --text chunking applied to the OCR output, especially useful if it is a large image with a lot of text, e.g.,<br>\n",
    "        a scanned page of a book - if the image contains a large text passage, it will be chunked and saved as<br>\n",
    "        potentially several individual text blocks, 'chunked' according to the text chunk size parameter.<br>\n",
    "        --a custom 'string' flag in special_field1 that indicates the text was created by an OCR, and includes a<br>\n",
    "        reference to the original doc_ID and block_ID<br>\n",
    "        --optional threshold for length of OCR to text to capture, e.g., if <10 characters captured, then may be<br>\n",
    "        preferable to skip (higher probability that image is noisy)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\hsyyu\\appdata\\roaming\\python\\python311\\site-packages (from pytesseract) (23.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\hsyyu\\anaconda3\\lib\\site-packages (from pytesseract) (10.3.0)\n",
      "Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.10\n"
     ]
    }
   ],
   "source": [
    "!pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llmware.library import Library\n",
    "from llmware.configs import LLMWareConfig\n",
    "from llmware.resources import CollectionRetrieval, CollectionWriter\n",
    "from llmware.parsers import ImageParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from importlib import util\n",
    "if not util.find_spec(\"pytesseract\"):\n",
    "    print(\"\\nto run this example requires additional dependencies, including pytesseract - see comments above in \"\n",
    "          \"this script.  to install pytesseract:  pip3 install pytesseract.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ocr_images_in_library(library_name, add_new_text_block=False, chunk_size=400, min_chars=10):\n",
    "    lib = Library().load_library(library_name)\n",
    "    image_path = lib.image_path\n",
    "\n",
    "    #   check here to see the images extracted from the original parsing\n",
    "    print(\"update: image source file path: \", image_path)\n",
    "\n",
    "    #   query the collection DB by content_type == \"image\"\n",
    "    image_blocks = CollectionRetrieval(library_name).filter_by_key(\"content_type\", \"image\")\n",
    "    doc_update_list = {}\n",
    "    new_text_created = 0\n",
    "\n",
    "    #   iterate through the image blocks found\n",
    "    for i, block in enumerate(image_blocks):\n",
    "\n",
    "        #   \"external_files\" points to the image name that will be found in the image_path above for the library\n",
    "        img_name = block[\"external_files\"]\n",
    "\n",
    "        #   each doc_ID is unique for the library collection\n",
    "        doc_id = block[\"doc_ID\"]\n",
    "\n",
    "        #   block_IDs are unique only for the document, and generally run in sequential ascending order\n",
    "        block_id = block[\"block_ID\"]\n",
    "\n",
    "        #   note: _id not used, but it is a good lookup key that can be easily inserted in special_field1 below\n",
    "        bid = block[\"_id\"]\n",
    "\n",
    "        #   preserve_spacing == True will keep \\n \\r \\t and other white space\n",
    "        #   preserve_spacing == False collapses the white space into a single space for 'more dense' text only\n",
    "        output = ImageParser(text_chunk_size=chunk_size).process_ocr(image_path,img_name,preserve_spacing=False)\n",
    "        print(\"update: ocr output: \", output)\n",
    "\n",
    "        #   note: test before writing to the collection\n",
    "        if add_new_text_block:\n",
    "            for text_chunk in output:\n",
    "                if text_chunk.strip():\n",
    "                    # optional to keep only more substantial chunks of text\n",
    "                    if len(text_chunk) > min_chars:\n",
    "                        #   ad hoc tracker to keep incrementing the block_id for every new image in a particular doc\n",
    "                        if doc_id in doc_update_list:\n",
    "                            new_block_id = doc_update_list[doc_id]\n",
    "                            doc_update_list.update({doc_id: new_block_id+1})\n",
    "                        else:\n",
    "                            new_block_id = 100000\n",
    "                            doc_update_list.update({doc_id: new_block_id+1})\n",
    "                        new_block = block\n",
    "                        #   feel free to adapt these attributes to fit for purpose\n",
    "                        new_block.update({\"block_ID\": new_block_id})\n",
    "                        new_block.update({\"content_type\": \"text\"})\n",
    "                        new_block.update({\"embedding_flags\": {}})\n",
    "                        new_block.update({\"text_search\": text_chunk})\n",
    "                        new_block.update({\"special_field1\": f\"OCR applied to image in document - \"\n",
    "                                                            f\"{doc_id} - block - {block_id}\"})\n",
    "                        #   new _id will be assigned by the database directly\n",
    "                        if \"_id\" in new_block:\n",
    "                            del new_block[\"_id\"]\n",
    "                        print(\"update: writing new text block - \", new_text_created, doc_id, block_id, text_chunk, new_block)\n",
    "                        #   creates the new record\n",
    "                        CollectionWriter(ln).write_new_parsing_record(new_block)\n",
    "                        new_text_created += 1\n",
    "    return new_text_created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "connection failed: could not receive data from server: Socket is not connected (0x00002749/10057)\ncould not send SSL negotiation packet: Socket is not connected (0x00002749/10057)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m ln \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_library\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     10\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/path/to/pdf_or_office_files_with_images/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m lib \u001b[38;5;241m=\u001b[39m \u001b[43mLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_new_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mln\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#   parse the documents\u001b[39;00m\n\u001b[0;32m     14\u001b[0m lib\u001b[38;5;241m.\u001b[39madd_files(fp, get_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,get_tables\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m400\u001b[39m, max_chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m,\n\u001b[0;32m     15\u001b[0m               smart_chunking\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose_level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\llmware\\library.py:145\u001b[0m, in \u001b[0;36mLibrary.create_new_library\u001b[1;34m(self, library_name, account_name)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# apply safety check to library_name path\u001b[39;00m\n\u001b[0;32m    143\u001b[0m library_name \u001b[38;5;241m=\u001b[39m Utilities()\u001b[38;5;241m.\u001b[39msecure_filename(library_name)\n\u001b[1;32m--> 145\u001b[0m library_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_if_library_exists\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43maccount_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m library_exists:\n\u001b[0;32m    148\u001b[0m     \u001b[38;5;66;03m# do not create\u001b[39;00m\n\u001b[0;32m    149\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdate: library already exists - returning library - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, library_name, account_name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\llmware\\library.py:302\u001b[0m, in \u001b[0;36mLibrary.check_if_library_exists\u001b[1;34m(self, library_name, account_name)\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Check if library exists by library string name \"\"\"\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# first look in library catalog\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m library_card \u001b[38;5;241m=\u001b[39m \u001b[43mLibraryCatalog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mget_library_card(library_name, account_name\u001b[38;5;241m=\u001b[39maccount_name)\n\u001b[0;32m    304\u001b[0m \u001b[38;5;66;03m# check file path\u001b[39;00m\n\u001b[0;32m    305\u001b[0m lib_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(LLMWareConfig\u001b[38;5;241m.\u001b[39mget_library_path(), account_name, library_name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\llmware\\library.py:820\u001b[0m, in \u001b[0;36mLibraryCatalog.__init__\u001b[1;34m(self, library, library_path, account_name)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m LLMWareTableSchema()\u001b[38;5;241m.\u001b[39mget_library_card_schema()\n\u001b[0;32m    819\u001b[0m \u001b[38;5;66;03m# if table does not exist, then create\u001b[39;00m\n\u001b[1;32m--> 820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mCollectionWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlibrary\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43maccount_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccount_name\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcheck_if_table_build_required():\n\u001b[0;32m    821\u001b[0m     CollectionWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary\u001b[39m\u001b[38;5;124m\"\u001b[39m, account_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccount_name)\u001b[38;5;241m.\u001b[39mcreate_table(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibrary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;66;03m# check for llmware path & create if not already set up\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\llmware\\resources.py:215\u001b[0m, in \u001b[0;36mCollectionWriter.__init__\u001b[1;34m(self, library_name, account_name, db_name, custom_table, custom_schema)\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m MongoWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlibrary_name, account_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccount_name, custom_table\u001b[38;5;241m=\u001b[39mcustom_table,\n\u001b[0;32m    212\u001b[0m                                custom_schema\u001b[38;5;241m=\u001b[39mcustom_schema)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_db \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpostgres\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m \u001b[43mPGWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccount_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccount_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_table\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_table\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    216\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcustom_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_schema\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactive_db \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_writer \u001b[38;5;241m=\u001b[39m SQLiteWriter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlibrary_name, account_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccount_name, custom_table\u001b[38;5;241m=\u001b[39mcustom_table,\n\u001b[0;32m    220\u001b[0m                                 custom_schema\u001b[38;5;241m=\u001b[39mcustom_schema)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\llmware\\resources.py:1445\u001b[0m, in \u001b[0;36mPGWriter.__init__\u001b[1;34m(self, library_name, account_name, custom_table, custom_schema)\u001b[0m\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlibrary_name \u001b[38;5;241m=\u001b[39m library_name\n\u001b[0;32m   1443\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccount_name \u001b[38;5;241m=\u001b[39m account_name\n\u001b[1;32m-> 1445\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn \u001b[38;5;241m=\u001b[39m \u001b[43m_PGConnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;66;03m#   simple lookup of schema by supported table type\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m library_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\llmware\\resources.py:3058\u001b[0m, in \u001b[0;36m_PGConnect.connect\u001b[1;34m(self, db_name, collection_name)\u001b[0m\n\u001b[0;32m   3053\u001b[0m \u001b[38;5;66;03m#   postgres will use the configured db name\u001b[39;00m\n\u001b[0;32m   3054\u001b[0m \u001b[38;5;66;03m# if db_name: self.postgres_db_name = db_name\u001b[39;00m\n\u001b[0;32m   3056\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostgres_db_name \u001b[38;5;241m=\u001b[39m PostgresConfig()\u001b[38;5;241m.\u001b[39mget_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdb_name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 3058\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn \u001b[38;5;241m=\u001b[39m \u001b[43mpsycopg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostgres_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostgres_port\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdbname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostgres_db_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3059\u001b[0m \u001b[43m                            \u001b[49m\u001b[43muser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostgres_user_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpostgres_pw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconn\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\psycopg\\connection.py:749\u001b[0m, in \u001b[0;36mConnection.connect\u001b[1;34m(cls, conninfo, autocommit, prepare_threshold, row_factory, cursor_factory, context, **kwargs)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rv:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m last_ex\n\u001b[1;32m--> 749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m last_ex\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    751\u001b[0m rv\u001b[38;5;241m.\u001b[39m_autocommit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(autocommit)\n\u001b[0;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m row_factory:\n",
      "\u001b[1;31mOperationalError\u001b[0m: connection failed: could not receive data from server: Socket is not connected (0x00002749/10057)\ncould not send SSL negotiation packet: Socket is not connected (0x00002749/10057)"
     ]
    }
   ],
   "source": [
    "\n",
    "#   main execution script starts here\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #   select collection db - mongo, sqlite, or postgres\n",
    "    LLMWareConfig().set_active_db(\"postgres\")\n",
    "\n",
    "    #   create a library (source documents must have embedded images!)\n",
    "    ln = \"my_library\"\n",
    "    fp = \"/path/to/pdf_or_office_files_with_images/\"\n",
    "    lib = Library().create_new_library(ln)\n",
    "\n",
    "    #   parse the documents\n",
    "    lib.add_files(fp, get_images=True,get_tables=True, chunk_size=400, max_chunk_size=600,\n",
    "                  smart_chunking=1, verbose_level=2)\n",
    "\n",
    "    print(\"done parsing\")\n",
    "\n",
    "    #   runs ocr on the images in the newly-created library\n",
    "    #   set add_new_text_block == True to add new rows in the database (otherwise, will just run the OCR in memory)\n",
    "    new_blocks = ocr_images_in_library(ln,add_new_text_block=False,chunk_size=400, min_chars=10)\n",
    "\n",
    "    print(\"done with ocr processing\")\n",
    "\n",
    "    g = CollectionRetrieval(ln).get_whole_collection()\n",
    "\n",
    "    #   may need to loop through the iterator if extremely large collection (otherwise, pull_all into memory OK)\n",
    "\n",
    "    blocks = g.pull_all()\n",
    "\n",
    "    ocr_count = 0\n",
    "\n",
    "    #   look at the new text entries created and inserted into the collection\n",
    "    for i, b in enumerate(blocks):\n",
    "        if b[\"block_ID\"] > 9999:\n",
    "            print(\"update: new ocr text entry: \", ocr_count, b[\"doc_ID\"], b[\"block_ID\"], b[\"content_type\"],\n",
    "                  b[\"special_field1\"], b[\"text_search\"])\n",
    "\n",
    "            ocr_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  main execution script starts here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
