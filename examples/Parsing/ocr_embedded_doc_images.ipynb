{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " Example:   ** Applying OCR to Images in LLMWare Library **<br>\n",
    "    This example shows how to:<br>\n",
    "    A.  identify images in a library (post the initial parsing)<br>\n",
    "    B.  run an OCR against the images to derive the text from the image using the OCR<br>\n",
    "    C.  insert the text into the database library collection for subsequent retrieval.<br>\n",
    "    Note: this example uses additional python dependencies:<br>\n",
    "        -- pip3 install pytesseract<br>\n",
    "    Note: this example uses an OCR engine, which is outside of the core llmware package.  To install on Ubuntu:<br>\n",
    "        -- sudo apt install tesseract-ocr<br>\n",
    "        -- sudo apt install libtesseract-dev<br>\n",
    "    [Other platforms:<br>\n",
    "        -- Mac: brew install tesseract<br>\n",
    "        -- Windows:   GUI download installer - see UB-Mannheim @ www.github.com/UB-Mannheim/tesseract/wiki<br>\n",
    "    Running this script will NOT make any changes to the original \"image\" block record in the text collection.<br>\n",
    "    Rather than update/replace the existing record, the script will create a new supplemental entry for each 'image'.<br>\n",
    "    Each new record will have the following attributes:<br>\n",
    "        --\"text\" block with the text derived from the OCR, including the original source doc_ID, file source name and<br>\n",
    "        page number for easy reference<br>\n",
    "        --new block_ID starting at 100000 (safely out of the 'block namespace' of the original document, and easy to<br>\n",
    "            identify as 'derived' text from an OCR, rather than an original part of the document<br>\n",
    "        --text chunking applied to the OCR output, especially useful if it is a large image with a lot of text, e.g.,<br>\n",
    "        a scanned page of a book - if the image contains a large text passage, it will be chunked and saved as<br>\n",
    "        potentially several individual text blocks, 'chunked' according to the text chunk size parameter.<br>\n",
    "        --a custom 'string' flag in special_field1 that indicates the text was created by an OCR, and includes a<br>\n",
    "        reference to the original doc_ID and block_ID<br>\n",
    "        --optional threshold for length of OCR to text to capture, e.g., if <10 characters captured, then may be<br>\n",
    "        preferable to skip (higher probability that image is noisy)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llmware.library import Library\n",
    "from llmware.configs import LLMWareConfig\n",
    "from llmware.resources import CollectionRetrieval, CollectionWriter\n",
    "from llmware.parsers import ImageParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import util\n",
    "if not util.find_spec(\"pytesseract\"):\n",
    "    print(\"\\nto run this example requires additional dependencies, including pytesseract - see comments above in \"\n",
    "          \"this script.  to install pytesseract:  pip3 install pytesseract.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_images_in_library(library_name, add_new_text_block=False, chunk_size=400, min_chars=10):\n",
    "    lib = Library().load_library(library_name)\n",
    "    image_path = lib.image_path\n",
    "\n",
    "    #   check here to see the images extracted from the original parsing\n",
    "    print(\"update: image source file path: \", image_path)\n",
    "\n",
    "    #   query the collection DB by content_type == \"image\"\n",
    "    image_blocks = CollectionRetrieval(library_name).filter_by_key(\"content_type\", \"image\")\n",
    "    doc_update_list = {}\n",
    "    new_text_created = 0\n",
    "\n",
    "    #   iterate through the image blocks found\n",
    "    for i, block in enumerate(image_blocks):\n",
    "\n",
    "        #   \"external_files\" points to the image name that will be found in the image_path above for the library\n",
    "        img_name = block[\"external_files\"]\n",
    "\n",
    "        #   each doc_ID is unique for the library collection\n",
    "        doc_id = block[\"doc_ID\"]\n",
    "\n",
    "        #   block_IDs are unique only for the document, and generally run in sequential ascending order\n",
    "        block_id = block[\"block_ID\"]\n",
    "\n",
    "        #   note: _id not used, but it is a good lookup key that can be easily inserted in special_field1 below\n",
    "        bid = block[\"_id\"]\n",
    "\n",
    "        #   preserve_spacing == True will keep \\n \\r \\t and other white space\n",
    "        #   preserve_spacing == False collapses the white space into a single space for 'more dense' text only\n",
    "        output = ImageParser(text_chunk_size=chunk_size).process_ocr(image_path,img_name,preserve_spacing=False)\n",
    "        print(\"update: ocr output: \", output)\n",
    "\n",
    "        #   note: test before writing to the collection\n",
    "        if add_new_text_block:\n",
    "            for text_chunk in output:\n",
    "                if text_chunk.strip():\n",
    "                    # optional to keep only more substantial chunks of text\n",
    "                    if len(text_chunk) > min_chars:\n",
    "                        #   ad hoc tracker to keep incrementing the block_id for every new image in a particular doc\n",
    "                        if doc_id in doc_update_list:\n",
    "                            new_block_id = doc_update_list[doc_id]\n",
    "                            doc_update_list.update({doc_id: new_block_id+1})\n",
    "                        else:\n",
    "                            new_block_id = 100000\n",
    "                            doc_update_list.update({doc_id: new_block_id+1})\n",
    "                        new_block = block\n",
    "                        #   feel free to adapt these attributes to fit for purpose\n",
    "                        new_block.update({\"block_ID\": new_block_id})\n",
    "                        new_block.update({\"content_type\": \"text\"})\n",
    "                        new_block.update({\"embedding_flags\": {}})\n",
    "                        new_block.update({\"text_search\": text_chunk})\n",
    "                        new_block.update({\"special_field1\": f\"OCR applied to image in document - \"\n",
    "                                                            f\"{doc_id} - block - {block_id}\"})\n",
    "                        #   new _id will be assigned by the database directly\n",
    "                        if \"_id\" in new_block:\n",
    "                            del new_block[\"_id\"]\n",
    "                        print(\"update: writing new text block - \", new_text_created, doc_id, block_id, text_chunk, new_block)\n",
    "                        #   creates the new record\n",
    "                        CollectionWriter(ln).write_new_parsing_record(new_block)\n",
    "                        new_text_created += 1\n",
    "    return new_text_created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  main execution script starts here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
