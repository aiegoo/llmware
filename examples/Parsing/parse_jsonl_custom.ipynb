{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n This script illustrates options for parsing JSON and JSONL files into a Library in LLMWare, including the ability<br>\n", "    to provide a custom configured mapping intended for use with 'pseudo-db' structured JSON and JSONL files<br>\n", "    Option # 1- Standard JSON/JSON parsing -<br>\n", "        --  when using a bulk ingest Parsing method, the parser will route json and jsonl files to the 'standard'<br>\n", "            TextParser - which will look for a \"text\" key in the JSON/JSONL to extract as the intended text<br>\n", "        --  if no 'text' key found, then the parse will return an empty output list []<br>\n", "        --  you can provide an optional key_list parameter to TextParser, which will then by default capture the<br>\n", "            selected fields and aggregate to form the text input, e.g.,<br>\n", "            TextParser().jsonl_file_handler(fp,fn, key_list=[\"context\", \"source\", \"ID\"]<br>\n", "            ... where \"context\", \"source\" and \"ID\" represent keys found in the source json/jsonl file<br>\n", "        -- the standard TextParser() is designed for ad hoc extraction of text content, not to preserve the keys<br>\n", "        -- use of this method is shown in the first example below<br>\n", "    Option # 2- Custom Configured JSON/JSONL parsing -<br>\n", "        -- in addition to the standard parsing method, there is the ability to customize the mappings for a<br>\n", "        JSON/JSONL file in which the keys are intended to be used for follow-up lookup and retrieval<br>\n", "        -- Parser().parse_json_config method - this is shown in the second and third examples below<br>\n", "  \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llmware.parsers import Parser, TextParser\n", "from llmware.library import Library\n", "from llmware.retrieval import Query\n", "from llmware.configs import LLMWareConfig"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import time\n", "import ast"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  All three text databases supported (mongo, postgres, and sqlite)<br>\n", "  if it is highly varied unstructured content, we would recommend Mongo given its flexibility<br>\n", "  if any validation errors with Postgres or SQLite, then we would recommend either preprocessing the json or<br>\n", "  ... trying with Mongo"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["LLMWareConfig().set_active_db(\"mongo\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def standard_json_parsing(fp, fn):\n", "    \"\"\" This example shows the 'standard' text handler for json/jsonl \"\"\"\n\n", "    #   the selected keys should map to dictionary keys found in the JSON/JSONL\n", "    #   if no keys passed, then by default, parser will only look for a \"text\" key\n", "    #   the parser objective is extracting/aggregating the content of the file, not using the 'structure' of the keys\n", "    #   if interpret_as_table is True, then returns each row as a LIST of elements, corresponding to the selected keys\n", "    #   if interpret_as_table is False, then returns a text string, which is concatenation of the text found in each\n", "    #   key, and will use the value of the separator to combine each key,\n", "    #   e.g., value1 + separator + value2 + separator ...\n", "    selected_keys = [\"key1\", \"key2\", \"key3\"]    # e.g., \"context\", \"source\", \"ID\" or other keys in json\n", "    output = TextParser().jsonl_file_handler(fp,fn,key_list=selected_keys,interpret_as_table=False,separator=\"\\n\")\n", "    return output"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def configured_json_parsing(fp, fn, library_name):\n", "    \"\"\" This example shows how to use mappings for a customized json/jsonl \"\"\"\n\n", "    #   metadata is a dictionary mapping of key names to keys in the json file\n", "    #   the 'keys' correspond to the keys that will be added to the library\n", "    #   the 'values' correspond to the keys that will be found in the JSON/JSONL source file\n\n", "    #   metadata must have \"text\" mapping\n", "    #   if \"doc_ID\" or \"block_ID\" mapping provided, then will \"over-write\" the default doc_ID and block_ID and\n", "    #   use the mapping provided in the source JSON/JSONL\n\n", "    #   for all other attributes (e.g., not text, doc_ID, block_ID), the keys will be stored in \"special_field1\" of\n", "    #   the database.  For Mongo, the keys will be stored directly as a dictionary, while for Postgres and SQLite,\n", "    #   it will be stored as text string, which must be converted upon use back into a dictionary (see below for\n", "    #   retrieval example)\n\n", "    #   step 1 - create metadata mapping\n", "    #   -- must have 'text' key mapped to key in json source\n", "    #   -- all other keys are 'optional' and can be any number from 0 - N\n", "    #   -- generally, key2, etc. should map to the name of the key in the JSON file, although you are free to re-name\n", "    metadata= {\"text\": \"json_source_key_mapping_to_main_text_input\",\n", "               \"key2\": \"json_source_key2\",\n", "               \"key3\": \"key3\"}\n\n", "    #  step 2 - create new library\n", "    lib = Library().create_new_library(library_name)\n", "    parser = Parser(lib)\n\n", "    # step 3 - invoke parse_json_config method\n", "    print(\"step 1 - parsing\")\n", "    t0 = time.time()\n", "    parser_output = parser.parse_json_config(fp, fn, mapping_dict=metadata)\n", "    print(f\"done parsing - time - {time.time() - t0} - summary - {parser_output}\")\n", "    return parser_output"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}