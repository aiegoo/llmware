{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " This example shows how to get started using the ModelCatalog to instantiate models and start running inferences.<br>\n",
    "    A core design principle of LLMWare is that all models should be accessible in the same way, with the<br>\n",
    "    underlying configuration details handled at lower levels of the implementation.   Our aspiration is that you<br>\n",
    "    should be able to substitute models in any pipeline/workflow at any point with minimal, if any, code change -<br>\n",
    "    and to be able to deploy heterogeneous combinations of local, private network and API-based models,<br>\n",
    "    with mix-qnd-match and full 'swqp-ability' at any time.<br>\n",
    "    While LLMWare supports OpenAI and other API-based models, we are \"open-source-first\" in our view and<br>\n",
    "    support of models, and all of our examples and classes/methods are optimized first to work with small, specialized<br>\n",
    "    open source models.   Our view is that essentially anything that can be done with large API models can be<br>\n",
    "    replicated with smaller fine-tuned models and well-designed data pipelines and workflows.<br>\n",
    "    We provide over 50+ LLMWare models that are all tested and designed for easy integration<br>\n",
    "    into LLMWare pipeline and workflows, but we are 100% committed to providing an open ecosystem and supporting<br>\n",
    "    the best in open source, including leading embedding models from Jina and Nomic, Llama-2, Llama-3, Mistral,<br>\n",
    "    Phi-3, Yi, DeciLM, StableLM, OpenHermes, Tiny Llama, RedPajama, Pythia, Sheared LLama, Huggingface Zephyr,<br>\n",
    "    SentenceTransformers and quantizations from The Bloke and Bartowski.  We also provide a full integration into GGUF,<br>\n",
    "    LLama.CPP and Whisper.CPP.<br>\n",
    "    It is easy to extend the ModelCatalog to include any of your favorite models from<br>\n",
    "    HuggingFace, Ollama, LMStudio, LLama.CPP, or llama-cpp-python.<br>\n",
    "    For open source models, we generally support both PyTorch (Huggingface) based models, as well as GGUF (LLama.CPP)<br>\n",
    "    quantized models.  For most use cases, we find that GGUF quantized versions are faster, take less memory<br>\n",
    "    and are generally as accurate, so we use GGUF-based models, aka \"tools\", in many of our examples.<br>\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from llmware.models import ModelCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_models = ModelCatalog().list_all_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ~133 models in the catalog as of May 4, 2024 - and growing all the time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All Models\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAll Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models:  0 {'model_name': 'bert', 'display_name': 'Bert', 'model_family': 'BaseModel', 'model_category': 'base', 'model_location': 'llmware_repo'}\n",
      "models:  1 {'model_name': 'roberta', 'display_name': 'Roberta', 'model_family': 'BaseModel', 'model_category': 'base', 'model_location': 'llmware_repo'}\n",
      "models:  2 {'model_name': 'gpt2', 'display_name': 'GPT-2', 'model_family': 'BaseModel', 'model_category': 'base', 'model_location': 'llmware_repo'}\n",
      "models:  3 {'model_name': 'all-MiniLM-L6-v2', 'display_name': 'mini-lm-sbert', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 384, 'context_window': 512, 'link': 'https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'sentence-transformers/all-MiniLM-L6-v2'}\n",
      "models:  4 {'model_name': 'all-mpnet-base-v2', 'display_name': 'mpnet-base', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 514, 'link': 'https://huggingface.co/sentence-transformers/all-mpnet-base-v2', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'sentence-transformers/all-mpnet-base-v2'}\n",
      "models:  5 {'model_name': 'industry-bert-insurance', 'display_name': 'industry-bert-insurance', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 512, 'link': 'https://huggingface.co/llmware/industry-bert-insurance-v0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/industry-bert-insurance-v0.1'}\n",
      "models:  6 {'model_name': 'industry-bert-contracts', 'display_name': 'industry-bert-contracts', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 512, 'link': 'https://huggingface.co/llmware/industry-bert-contracts-v0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/industry-bert-contracts-v0.1'}\n",
      "models:  7 {'model_name': 'industry-bert-asset-management', 'display_name': 'industry-bert-asset-management', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 512, 'link': 'https://huggingface.co/llmware/industry-bert-asset-management-v0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/industry-bert-asset-management-v0.1'}\n",
      "models:  8 {'model_name': 'industry-bert-sec', 'display_name': 'industry-bert-sec', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 512, 'link': 'https://huggingface.co/llmware/industry-bert-sec-v0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/industry-bert-sec-v0.1'}\n",
      "models:  9 {'model_name': 'nomic-ai/nomic-embed-text-v1', 'display_name': 'nomic-text-v1', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 8192, 'link': 'https://huggingface.co/nomic-ai/nomic-embed-text-v1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'nomic-ai/nomic-embed-text-v1'}\n",
      "models:  10 {'model_name': 'jinaai/jina-embeddings-v2-base-en', 'display_name': 'jina-base-en-v2', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 8192, 'link': 'https://huggingface.co/jinaai/jina-embeddings-v2-base-en', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'jinaai/jina-embeddings-v2-base-en'}\n",
      "models:  11 {'model_name': 'jinaai/jina-embeddings-v2-small-en', 'display_name': 'jina-small-en-v2', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 512, 'context_window': 8192, 'link': 'https://huggingface.co/jinaai/jina-embeddings-v2-small-en', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'jinaai/jina-embeddings-v2-small-en'}\n",
      "models:  12 {'model_name': 'BAAI/bge-small-en-v1.5', 'display_name': 'bge-small-en-v1.5', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 384, 'context_window': 512, 'link': 'https://huggingface.co/BAAI/bge-small-en-v1.5', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'BAAI/bge-small-en-v1.5'}\n",
      "models:  13 {'model_name': 'BAAI/bge-large-en-v1.5', 'display_name': 'bge-large-en-v1.5', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 1024, 'context_window': 512, 'link': 'https://huggingface.co/BAAI/bge-large-en-v1.5', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'BAAI/bge-large-en-v1.5'}\n",
      "models:  14 {'model_name': 'BAAI/bge-base-en-v1.5', 'display_name': 'bge-base-en-v1.5', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 512, 'link': 'https://huggingface.co/BAAI/bge-base-en-v1.5', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'BAAI/bge-base-en-v1.5'}\n",
      "models:  15 {'model_name': 'thenlper/gte-small', 'display_name': 'gte-small', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 384, 'context_window': 512, 'link': 'https://huggingface.co/thenlper/gte-small', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'thenlper/gte-small'}\n",
      "models:  16 {'model_name': 'thenlper/gte-base', 'display_name': 'gte-base', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 768, 'context_window': 512, 'link': 'https://huggingface.co/thenlper/gte-base', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'thenlper/gte-base'}\n",
      "models:  17 {'model_name': 'thenlper/gte-large', 'display_name': 'gte-large', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 1024, 'context_window': 512, 'link': 'https://huggingface.co/thenlper/gte-large', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'thenlper/gte-large'}\n",
      "models:  18 {'model_name': 'llmrails/ember-v1', 'display_name': 'ember-v1', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 1024, 'context_window': 512, 'link': 'https://huggingface.co/llmrails/ember-v1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmrails/ember-v1'}\n",
      "models:  19 {'model_name': 'WhereIsAI/UAE-Large-V1', 'display_name': 'uae-large-v1', 'model_family': 'HFEmbeddingModel', 'model_category': 'embedding', 'model_location': 'hf_repo', 'embedding_dims': 1024, 'context_window': 512, 'link': 'https://huggingface.co/WhereIsAI/UAE-Large-V1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'WhereIsAI/UAE-Large-V1'}\n",
      "models:  20 {'model_name': 'text-embedding-ada-002', 'display_name': 'OpenAI-Embedding', 'model_family': 'OpenAIEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 8191, 'embedding_dims': 1536}\n",
      "models:  21 {'model_name': 'text-embedding-3-small', 'display_name': 'OpenAI-Embedding', 'model_family': 'OpenAIEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 8191, 'embedding_dims': 1536}\n",
      "models:  22 {'model_name': 'text-embedding-3-large', 'display_name': 'OpenAI-Embedding', 'model_family': 'OpenAIEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 8191, 'embedding_dims': 3072}\n",
      "models:  23 {'model_name': 'medium', 'display_name': 'Cohere-Medium-Embedding', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 4096}\n",
      "models:  24 {'model_name': 'xlarge', 'display_name': 'Cohere-XLarge-Embedding', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 4096}\n",
      "models:  25 {'model_name': 'embed-english-v3.0', 'display_name': 'Cohere-English-v3', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 1024}\n",
      "models:  26 {'model_name': 'embed-multilingual-v3.0', 'display_name': 'Cohere-Multi-Lingual-v3', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 1024}\n",
      "models:  27 {'model_name': 'embed-english-light-v3.0', 'display_name': 'Cohere-English-v3', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 384}\n",
      "models:  28 {'model_name': 'embed-multilingual-light-v3.0', 'display_name': 'Cohere-English-v3', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 384}\n",
      "models:  29 {'model_name': 'embed-english-v2.0', 'display_name': 'Cohere-English-v3', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 4096}\n",
      "models:  30 {'model_name': 'embed-english-light-v2.0', 'display_name': 'Cohere-English-v3', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 1024}\n",
      "models:  31 {'model_name': 'embed-multilingual-v2.0', 'display_name': 'Cohere-English-v3', 'model_family': 'CohereEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 2048, 'embedding_dims': 768}\n",
      "models:  32 {'model_name': 'textembedding-gecko@latest', 'display_name': 'Google-Embedding', 'model_family': 'GoogleEmbeddingModel', 'model_category': 'embedding', 'model_location': 'api', 'context_window': 4000, 'embedding_dims': 768}\n",
      "models:  33 {'model_name': 'claude-v1', 'display_name': 'Anthropic Claude-v1', 'model_family': 'ClaudeModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8000}\n",
      "models:  34 {'model_name': 'claude-instant-v1', 'display_name': 'claude-instant-1.2', 'model_family': 'ClaudeModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8000}\n",
      "models:  35 {'model_name': 'claude-3-opus-20240229', 'display_name': 'Anthropic-Claude-3-Opus', 'model_family': 'ClaudeModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8192}\n",
      "models:  36 {'model_name': 'claude-3-sonnet-20240229', 'display_name': 'Anthropic-Claude-3-Sonnet', 'model_family': 'ClaudeModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8192}\n",
      "models:  37 {'model_name': 'claude-2.1', 'display_name': 'Anthropic Claude-2.1', 'model_family': 'ClaudeModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8192}\n",
      "models:  38 {'model_name': 'claude-2.0', 'display_name': 'Anthropic Claude-Claude2-.0', 'model_family': 'ClaudeModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8192}\n",
      "models:  39 {'model_name': 'command-medium-nightly', 'display_name': 'Cohere Command Medium', 'model_family': 'CohereGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  40 {'model_name': 'command-xlarge-nightly', 'display_name': 'Cohere Command XLarge', 'model_family': 'CohereGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  41 {'model_name': 'summarize-xlarge', 'display_name': 'Cohere Summarize Xlarge', 'model_family': 'CohereGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  42 {'model_name': 'summarize-medium', 'display_name': 'Cohere Summarize Medium', 'model_family': 'CohereGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  43 {'model_name': 'j2-jumbo-instruct', 'display_name': 'Jurassic-2-Jumbo-Instruct', 'model_family': 'JurassicModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  44 {'model_name': 'j2-grande-instruct', 'display_name': 'Jurassic-2-Grande-Instruct', 'model_family': 'JurassicModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  45 {'model_name': 'text-bison@001', 'display_name': 'Google Palm', 'model_family': 'GoogleGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8192}\n",
      "models:  46 {'model_name': 'chat-bison@001', 'display_name': 'Google Chat', 'model_family': 'GoogleGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8192}\n",
      "models:  47 {'model_name': 'text-davinci-003', 'display_name': 'GPT3-Davinci', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 4096}\n",
      "models:  48 {'model_name': 'text-curie-001', 'display_name': 'GPT3-Curie', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  49 {'model_name': 'text-babbage-001', 'display_name': 'GPT3-Babbage', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  50 {'model_name': 'text-ada-001', 'display_name': 'GPT3-Ada', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  51 {'model_name': 'gpt-3.5-turbo', 'display_name': 'ChatGPT', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 4000}\n",
      "models:  52 {'model_name': 'gpt-4', 'display_name': 'GPT-4', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 8000}\n",
      "models:  53 {'model_name': 'gpt-3.5-turbo-instruct', 'display_name': 'GPT-3.5-Instruct', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 4000}\n",
      "models:  54 {'model_name': 'gpt-4-1106-preview', 'display_name': 'GPT-4-Turbo-1106', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 128000}\n",
      "models:  55 {'model_name': 'gpt-3.5-turbo-1106', 'display_name': 'GPT-3.5-Turbo-1106', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 16385}\n",
      "models:  56 {'model_name': 'gpt-4-0125-preview', 'display_name': 'GPT-4-Turbo-0125', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 128000}\n",
      "models:  57 {'model_name': 'gpt-3.5-turbo-0125', 'display_name': 'GPT-3.5-Turbo-0125', 'model_family': 'OpenAIGenModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 16385}\n",
      "models:  58 {'model_name': 'aib-read-gpt', 'display_name': 'AIB-READ-GPT', 'model_family': 'AIBReadGPTModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  59 {'model_name': 'llmware-inference-server', 'display_name': 'LLMWare-GPT', 'model_family': 'LLMWareModel', 'model_category': 'generative-api', 'model_location': 'api', 'context_window': 2048}\n",
      "models:  60 {'model_name': 'llmware/bling-1.4b-0.1', 'display_name': 'bling-1.4b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-1.4b-0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-1.4b-0.1'}\n",
      "models:  61 {'model_name': 'llmware/bling-1b-0.1', 'display_name': 'bling-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-1b-0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-1b-0.1'}\n",
      "models:  62 {'model_name': 'llmware/bling-falcon-1b-0.1', 'display_name': 'bling-falcon-1.3b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-falcon-1b-0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-falcon-1b-0.1'}\n",
      "models:  63 {'model_name': 'llmware/bling-sheared-llama-1.3b-0.1', 'display_name': 'bling-sheared-llama-1.3b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-sheared-llama-1.3b-0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-sheared-llama-1.3b-0.1'}\n",
      "models:  64 {'model_name': 'llmware/bling-red-pajamas-3b-0.1', 'display_name': 'bling-red-pajamas-3b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-red-pajamas-3b-0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-red-pajamas-3b-0.1'}\n",
      "models:  65 {'model_name': 'llmware/bling-sheared-llama-2.7b-0.1', 'display_name': 'bling-sheared-llama-2.7b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-sheared-llama-2.7b-0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-sheared-llama-2.7b-0.1'}\n",
      "models:  66 {'model_name': 'llmware/bling-stable-lm-3b-4e1t-v0', 'display_name': 'bling-stablelm-3b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-stable-lm-3b-4e1t-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-stable-lm-3b-4e1t-v0'}\n",
      "models:  67 {'model_name': 'llmware/bling-cerebras-1.3b-0.1', 'display_name': 'bling-cerebras-1.3b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-cerebras-1.3b-0.1', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-cerebras-1.3b-0.1'}\n",
      "models:  68 {'model_name': 'llmware/bling-tiny-llama-v0', 'display_name': 'bling-tiny-llama-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-tiny-llama-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-tiny-llama-v0'}\n",
      "models:  69 {'model_name': 'llmware/dragon-yi-6b-v0', 'display_name': 'dragon-yi-6b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '\\n', 'link': 'https://huggingface.co/llmware/dragon-yi-6b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-yi-6b-v0'}\n",
      "models:  70 {'model_name': 'llmware/dragon-stablelm-7b-v0', 'display_name': 'dragon-stablelm-7b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/dragon-stablelm-7b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-stablelm-7b-v0'}\n",
      "models:  71 {'model_name': 'llmware/dragon-mistral-7b-v0', 'display_name': 'dragon-mistral-7b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/dragon-mistral-7b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-mistral-7b-v0'}\n",
      "models:  72 {'model_name': 'llmware/dragon-red-pajama-7b-v0', 'display_name': 'dragon-red-pajama-7b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/dragon-red-pajama-7b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-red-pajama-7b-v0'}\n",
      "models:  73 {'model_name': 'llmware/dragon-deci-6b-v0', 'display_name': 'dragon-deci-6b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/dragon-deci-6b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-deci-6b-v0'}\n",
      "models:  74 {'model_name': 'llmware/dragon-falcon-7b-v0', 'display_name': 'dragon-falcon-7b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/dragon-falcon-7b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-falcon-7b-v0'}\n",
      "models:  75 {'model_name': 'llmware/dragon-llama-7b-v0', 'display_name': 'dragon-llama-7b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/dragon-llama-7b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-llama-7b-v0'}\n",
      "models:  76 {'model_name': 'llmware/dragon-deci-7b-v0', 'display_name': 'dragon-deci-7b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/dragon-deci-7b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/dragon-deci-7b-v0'}\n",
      "models:  77 {'model_name': 'llmware/bling-phi-3', 'display_name': 'bling-phi-3', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 4096, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/bling-phi-3', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/bling-phi-3'}\n",
      "models:  78 {'model_name': 'bling-phi-3-gguf', 'display_name': 'llmware/bling-phi-3-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 4096, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'trailing_space': '', 'gguf_file': 'bling-phi-3.gguf', 'gguf_repo': 'llmware/bling-phi-3-gguf', 'snapshot': True, 'link': 'https://huggingface.co/llmware/bling-phi-3-gguf', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  79 {'model_name': 'llmware/dragon-mistral-7b-gguf', 'display_name': 'dragon-mistral-7b-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'dragon-mistral-7b-q4_k_m.gguf', 'gguf_repo': 'llmware/dragon-mistral-7b-v0', 'link': 'https://huggingface.co/llmware/dragon-mistral-7b-v0', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  80 {'model_name': 'llmware/dragon-llama-7b-gguf', 'display_name': 'dragon-llama-7b-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'dragon-llama-7b-q4_k_m.gguf', 'gguf_repo': 'llmware/dragon-llama-7b-v0', 'link': 'https://huggingface.co/llmware/dragon-llama-7b-v0', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  81 {'model_name': 'llmware/dragon-yi-6b-gguf', 'display_name': 'dragon-yi-6b-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '\\n', 'gguf_file': 'dragon-yi-6b-q4_k_m.gguf', 'gguf_repo': 'llmware/dragon-yi-6b-v0', 'link': 'https://huggingface.co/llmware/dragon-yi-6b-v0', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  82 {'model_name': 'dragon-yi-answer-tool', 'display_name': 'dragon-yi-6b-answer-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '\\n', 'gguf_file': 'dragon-yi.gguf', 'gguf_repo': 'llmware/dragon-yi-answer-tool', 'snapshot': True, 'link': 'https://huggingface.co/llmware/dragon-yi-answer-tool', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  83 {'model_name': 'dragon-llama-answer-tool', 'display_name': 'dragon-llama-answer-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'dragon-llama.gguf', 'gguf_repo': 'llmware/dragon-llama-answer-tool', 'snapshot': True, 'link': 'https://huggingface.co/llmware/dragon-llama-answer-tool', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  84 {'model_name': 'dragon-mistral-answer-tool', 'display_name': 'dragon-mistral-answer-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'dragon-mistral.gguf', 'gguf_repo': 'llmware/dragon-mistral-answer-tool', 'snapshot': True, 'link': 'https://huggingface.co/llmware/dragon-mistral-answer-tool', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  85 {'model_name': 'TheBloke/Llama-2-7B-Chat-GGUF', 'display_name': 'llama-2-7b-chat-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': True, 'prompt_wrapper': '<INST>', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'llama-2-7b-chat.Q4_K_M.gguf', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  86 {'model_name': 'TheBloke/OpenHermes-2.5-Mistral-7B-GGUF', 'display_name': 'openhermes-mistral-7b-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': True, 'prompt_wrapper': 'chat_ml', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'openhermes-2.5-mistral-7b.Q4_K_M.gguf', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  87 {'model_name': 'TheBloke/zephyr-7B-beta-GGUF', 'display_name': 'zephyr-7b-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': True, 'prompt_wrapper': 'hf_chat', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'zephyr-7b-beta.Q4_K_M.gguf', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  88 {'model_name': 'TheBloke/Starling-LM-7B-alpha-GGUF', 'display_name': 'starling-7b-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': True, 'prompt_wrapper': 'open_chat', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'starling-lm-7b-alpha.Q4_K_M.gguf', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  89 {'model_name': 'microsoft/Phi-3-mini-4k-instruct-gguf', 'display_name': 'phi-3-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_windows': 4096, 'instruction_following': False, 'prompt_wrapper': 'phi_3', 'temperature': 0.3, 'trailing_space': '', 'gguf_file': 'Phi-3-mini-4k-instruct-q4.gguf', 'gguf_repo': 'microsoft/Phi-3-mini-4k-instruct-gguf', 'link': 'https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  90 {'model_name': 'microsoft/Phi-3-mini-4k-instruct', 'display_name': 'phi-3', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 4096, 'instruction_following': False, 'prompt_wrapper': 'phi_3', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'microsoft/Phi-3-mini-4k-instruct'}\n",
      "models:  91 {'model_name': 'microsoft/Phi-3-mini-128k-instruct', 'display_name': 'phi-3-128k', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 4096, 'instruction_following': False, 'prompt_wrapper': 'phi_3', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/microsoft/Phi-3-mini-128k-instruct-gguf', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'microsoft/Phi-3-mini-128k-instruct'}\n",
      "models:  92 {'model_name': 'Meta-Llama-3-8B-Instruct', 'display_name': 'llama-3-instruct', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 8192, 'instruction_following': False, 'prompt_wrapper': 'llama_3_chat', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/meta-llama/Meta-LLama-3-8B-instruct', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'meta-llama/Meta-Llama-3-8B-Instruct'}\n",
      "models:  93 {'model_name': 'Meta-Llama-3-8B', 'display_name': 'llama-3-base', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 8192, 'instruction_following': False, 'prompt_wrapper': 'llama_3_chat', 'temperature': 0.3, 'trailing_space': '', 'link': 'https://huggingface.co/meta-llama/Meta-LLama-3-8B', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'meta-llama/Meta-Llama-3-8B'}\n",
      "models:  94 {'model_name': 'QuantFactory/Meta-Llama-3-8B-Instruct-GGUF', 'display_name': 'llama-3-instruct-qf-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 8192, 'instruction_following': False, 'prompt_wrapper': 'llama_3', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'Meta-Llama-3-8B-Instruct.Q4_K_M.gguf', 'gguf_repo': 'QuantFactory/Meta-Llama-3-8B-Instruct-GGUF', 'link': 'https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  95 {'model_name': 'QuantFactory/Meta-Llama-3-8B-GGUF', 'display_name': 'llama-3-base-qf-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 8192, 'instruction_following': False, 'prompt_wrapper': 'llama_3', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'Meta-Llama-3-8B.Q4_K_M.gguf', 'gguf_repo': 'QuantFactory/Meta-Llama-3-8B-GGUF', 'link': 'https://huggingface.co/QuantFactory/Meta-Llama-3-GGUF', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  96 {'model_name': 'bartowski/Meta-Llama-3-8B-Instruct-GGUF', 'display_name': 'llama-3-instruct-bartowski-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 8192, 'instruction_following': False, 'prompt_wrapper': 'llama_3', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'Meta-Llama-3-8B-Instruct-Q4_K_M.gguf', 'gguf_repo': 'bartowski/Meta-Llama-3-8B-Instruct-GGUF', 'link': 'https://huggingface.co/bartowski/Meta-Llama-3-8B-Instruct-GGUF', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  97 {'model_name': 'tiny-llama-chat-gguf', 'display_name': 'tiny-llama-chat-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'hf_chat', 'temperature': 0.3, 'sample_default': True, 'trailing_space': '', 'gguf_file': 'tiny-llama-chat.gguf', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  98 {'model_name': 'whisper-cpp-base-english', 'display_name': 'whisper-en-base', 'model_family': 'WhisperCPPModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': '', 'temperature': 0.0, 'trailing_space': '', 'gguf_file': 'ggml-base.en.bin', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  99 {'model_name': 'whisper-cpp-base', 'display_name': 'whisper-base', 'model_family': 'WhisperCPPModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': '', 'temperature': 0.0, 'trailing_space': '', 'gguf_file': 'ggml-base.bin', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  100 {'model_name': 'whisper-cpp-tiny-diarize', 'display_name': 'whisper-en-tiny-diarize', 'model_family': 'WhisperCPPModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': '', 'temperature': 0.0, 'trailing_space': '', 'gguf_file': 'ggml-small.en-tdrz.bin', 'gguf_repo': 'llmware/bonchon', 'link': 'https://huggingface.co/llmware/bonchon', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  101 {'model_name': 'slim-ner-tool', 'display_name': 'slim-ner-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-ner.gguf', 'gguf_repo': 'llmware/slim-ner-tool', 'link': 'https://huggingface.co/llmware/slim-ner-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['people', 'location', 'organization', 'misc'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  102 {'model_name': 'slim-sentiment-tool', 'display_name': 'slim-sentiment-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-sentiment.gguf', 'gguf_repo': 'llmware/slim-sentiment-tool', 'link': 'https://huggingface.co/llmware/slim-sentiment-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['sentiment'], 'fc_output_values': ['positive', 'neutral', 'negative'], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [1066, 22198, 17821], 'marker_token_lookup': {1066: 'positive', 22198: 'negative', 17821: 'neutral'}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  103 {'model_name': 'slim-emotions-tool', 'display_name': 'slim-emotions-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-emotions.gguf', 'gguf_repo': 'llmware/slim-emotions-tool', 'link': 'https://huggingface.co/llmware/slim-emotions-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['emotions'], 'fc_output_values': ['afraid', 'anger', 'angry', 'annoyed', 'anticipating', 'anxious', 'apprehensive', 'ashamed', 'caring', 'confident', 'content', 'devastated', 'disappointed', 'disgusted', 'embarrassed', 'excited', 'faithful', 'fear', 'furious', 'grateful', 'guilty', 'hopeful', 'impressed', 'jealous', 'joy', 'joyful', 'lonely', 'love', 'nostalgic', 'prepared', 'proud', 'sad', 'sadness', 'sentimental', 'surprise', 'surprised', 'terrified', 'trusting'], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  104 {'model_name': 'slim-ratings-tool', 'display_name': 'slim-ratings-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-ratings.gguf', 'gguf_repo': 'llmware/slim-ratings-tool', 'link': 'https://huggingface.co/llmware/slim-ratings-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['rating'], 'fc_output_values': ['1', '2', '3', '4', '5'], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  105 {'model_name': 'slim-intent-tool', 'display_name': 'slim-intent-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-intent.gguf', 'gguf_repo': 'llmware/slim-intent-tool', 'link': 'https://huggingface.co/llmware/slim-intent-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['intent'], 'fc_output_values': ['account', 'cancel', 'complaint', 'customer service', 'delivery', 'feedback', 'invoice', 'new account', 'order', 'payments', 'refund', 'shipping', 'subscription', 'terminate'], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  106 {'model_name': 'slim-nli-tool', 'display_name': 'slim-nli-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-nli.gguf', 'gguf_repo': 'llmware/slim-nli-tool', 'link': 'https://huggingface.co/llmware/slim-nli-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['evidence'], 'fc_output_values': ['supports', 'neutral', 'contradicts'], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [9996, 5924, 17821], 'marker_token_lookup': {9996: 'contradicts', 5924: 'supports', 17821: 'neutral'}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  107 {'model_name': 'slim-topics-tool', 'display_name': 'slim-topics-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-topics.gguf', 'gguf_repo': 'llmware/slim-topics-tool', 'link': 'https://huggingface.co/llmware/slim-topics-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['topics'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  108 {'model_name': 'slim-tags-tool', 'display_name': 'slim-tags-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-tags.gguf', 'gguf_repo': 'llmware/slim-tags-tool', 'link': 'https://huggingface.co/llmware/slim-tags-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['tags'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  109 {'model_name': 'slim-sql-tool', 'display_name': 'slim-sql-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-sql.gguf', 'gguf_repo': 'llmware/slim-sql-tool', 'fc_output_values': [], 'link': 'https://huggingface.co/llmware/slim-sql-tool', 'custom_model_files': [], 'custom_model_repo': '', 'tokenizer': 'llmware/slim-sql-1b-v0', 'snapshot': True}\n",
      "models:  110 {'model_name': 'bling-answer-tool', 'display_name': 'bling-answer-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'bling-answer.gguf', 'gguf_repo': 'llmware/bling-answer-tool', 'link': 'https://huggingface.co/llmware/bling-answer-tool', 'custom_model_files': [], 'custom_model_repo': '', 'tokenizer': 'llmware/bling-tiny-llama-1b-v0', 'snapshot': True}\n",
      "models:  111 {'model_name': 'slim-category-tool', 'display_name': 'slim-category-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.3, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-category.gguf', 'gguf_repo': 'llmware/slim-category-tool', 'link': 'https://huggingface.co/llmware/slim-category-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['category'], 'fc_output_values': ['analyst', 'announcements', 'bonds', 'business', 'central bank', 'commentary', 'commodities', 'currencies', 'dividend', 'earnings', 'energy', 'entertainment', 'financials', 'health', 'human resources', 'legal and regulation', 'macroeconomics', 'markets', 'mergers and acquisitions', 'opinion', 'politics', 'public markets', 'science', 'sports', 'stocks', 'tech', 'world'], 'tokenizer': 'llmware/slim-sentiment', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  112 {'model_name': 'llmware/slim-intent', 'display_name': 'slim-intent-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-intent', 'hf_repo': 'llmware/slim-intent', 'custom_model_files': [''], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['intent'], 'fc_output_values': ['account', 'cancel', 'complaint', 'customer service', 'delivery', 'feedback', 'invoice', 'new account', 'order', 'payments', 'refund', 'shipping', 'subscription', 'terminate'], 'function': ['classify'], 'marker_tokens': [1066, 22198, 17821], 'marker_token_lookup': {1066: 'positive', 22198: 'negative', 17821: 'neutral'}}\n",
      "models:  113 {'model_name': 'llmware/slim-sentiment', 'display_name': 'slim-sentiment-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-sentiment', 'hf_repo': 'llmware/slim-sentiment', 'custom_model_files': [''], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['sentiment'], 'fc_output_values': ['positive', 'neutral', 'negative'], 'marker_tokens': [1066, 22198, 17821], 'marker_token_lookup': {1066: 'positive', 22198: 'negative', 17821: 'neutral'}, 'function': ['classify']}\n",
      "models:  114 {'model_name': 'llmware/slim-emotions', 'display_name': 'slim-emotions-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-emotions', 'hf_repo': 'llmware/slim-emotions', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['emotions'], 'fc_output_values': ['afraid', 'anger', 'angry', 'annoyed', 'anticipating', 'anxious', 'apprehensive', 'ashamed', 'caring', 'confident', 'content', 'devastated', 'disappointed', 'disgusted', 'embarrassed', 'excited', 'faithful', 'fear', 'furious', 'grateful', 'guilty', 'hopeful', 'impressed', 'jealous', 'joy', 'joyful', 'lonely', 'love', 'nostalgic', 'prepared', 'proud', 'sad', 'sadness', 'sentimental', 'surprise', 'surprised', 'terrified', 'trusting'], 'marker_tokens': [1066, 22198, 17821], 'marker_token_lookup': {1066: 'positive', 22198: 'negative', 17821: 'neutral'}, 'function': ['classify']}\n",
      "models:  115 {'model_name': 'llmware/slim-ner', 'display_name': 'slim-ner-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-ner', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'hf_repo': 'llmware/slim-ner', 'function_call': True, 'primary_keys': ['person', 'organization', 'place', 'misc'], 'fc_output_values': [], 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify']}\n",
      "models:  116 {'model_name': 'llmware/slim-nli', 'display_name': 'slim-nli-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-nli', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/slim-nli', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['evidence'], 'fc_output_values': ['supports', 'neutral', 'contradicts'], 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify']}\n",
      "models:  117 {'model_name': 'llmware/slim-ratings', 'display_name': 'slim-ratings-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-ratings', 'hf_repo': 'llmware/slim-ratings', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['rating'], 'fc_output_values': ['1', '2', '3', '4', '5'], 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify']}\n",
      "models:  118 {'model_name': 'llmware/slim-category', 'display_name': 'slim-category-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-category', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'hf_repo': 'llmware/slim-category', 'function_call': True, 'primary_keys': ['category'], 'fc_output_values': ['analyst', 'announcements', 'bonds', 'business', 'central bank', 'commentary', 'commodities', 'currencies', 'dividend', 'earnings', 'energy', 'entertainment', 'financials', 'health', 'human resources', 'legal and regulation', 'macroeconomics', 'markets', 'mergers and acquisitions', 'opinion', 'politics', 'public markets', 'science', 'sports', 'stocks', 'tech', 'world'], 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify']}\n",
      "models:  119 {'model_name': 'llmware/slim-tags', 'display_name': 'slim-tags-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-tags', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/slim-tags', 'outout_type': 'dict', 'function_call': True, 'marker_tokens': [], 'marker_token_lookup': {}, 'primary_keys': ['tags'], 'fc_output_values': [], 'function': ['classify']}\n",
      "models:  120 {'model_name': 'llmware/slim-topics', 'display_name': 'slim-topics-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-topics', 'hf_repo': 'llmware/slim-topics', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'marker_tokens': [], 'marker_token_lookup': {}, 'primary_keys': ['topics'], 'fc_output_values': [], 'function': ['classify']}\n",
      "models:  121 {'model_name': 'llmware/slim-sql-1b-v0', 'display_name': 'slim-sql-1b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'link': 'https://huggingface.co/llmware/slim-sql-1b-v0', 'custom_model_files': [], 'custom_model_repo': '', 'hf_repo': 'llmware/slim-sql-1b-v0', 'function_call': False, 'fc_output_values': [], 'primary_keys': ['sql'], 'function': ['sql']}\n",
      "models:  122 {'model_name': 'bling-stablelm-3b-tool', 'display_name': 'llmware/bling-stablelm-3b-gguf', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'bling-stablelm.gguf', 'gguf_repo': 'llmware/bling-stablelm-3b-gguf', 'snapshot': True, 'link': 'https://huggingface.co/llmware/bling-stablelm-3b-gguf', 'custom_model_files': [], 'custom_model_repo': ''}\n",
      "models:  123 {'model_name': 'slim-xsum', 'display_name': 'llmware/slim-xsum', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-xsum', 'hf_repo': 'llmware/slim-xsum', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'marker_tokens': [], 'marker_token_lookup': {}, 'primary_keys': ['xsum'], 'fc_output_values': [], 'function': ['classify']}\n",
      "models:  124 {'model_name': 'slim-xsum-tool', 'display_name': 'slim-xsum-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-xsum.gguf', 'gguf_repo': 'llmware/slim-xsum-tool', 'link': 'https://huggingface.co/llmware/slim-xsum-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['xsum'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-extract', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  125 {'model_name': 'slim-extract', 'display_name': 'llmware/slim-extract', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-extract', 'hf_repo': 'llmware/slim-extract', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'marker_tokens': [], 'marker_token_lookup': {}, 'primary_keys': ['key data points'], 'fc_output_values': [], 'function': ['extract']}\n",
      "models:  126 {'model_name': 'slim-extract-tool', 'display_name': 'slim-extract-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-extract.gguf', 'gguf_repo': 'llmware/slim-extract-tool', 'link': 'https://huggingface.co/llmware/slim-extract-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['key data points'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-extract', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['extract'], 'snapshot': True}\n",
      "models:  127 {'model_name': 'slim-boolean', 'display_name': 'llmware/slim-boolean', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-boolean', 'hf_repo': 'llmware/slim-boolean', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'marker_tokens': [2369, 9820], 'marker_token_lookup': {2369: 'no', 9820: 'yes'}, 'primary_keys': [], 'fc_output_values': [], 'function': ['boolean']}\n",
      "models:  128 {'model_name': 'slim-boolean-tool', 'display_name': 'slim-boolean-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-boolean.gguf', 'gguf_repo': 'llmware/slim-boolean-tool', 'link': 'https://huggingface.co/llmware/slim-boolean-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': [], 'fc_output_values': [], 'tokenizer': 'llmware/slim-extract', 'marker_tokens': [2369, 9820], 'marker_token_lookup': {2369: 'no', 9820: 'yes'}, 'function': ['boolean'], 'snapshot': True}\n",
      "models:  129 {'model_name': 'slim-sa-ner', 'display_name': 'llmware/slim-sa-ner', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-sa-ner', 'hf_repo': 'llmware/slim-sa-ner', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'marker_tokens': [], 'marker_token_lookup': {}, 'primary_keys': ['sentiment, person, organization, place'], 'fc_output_values': [], 'function': ['classify']}\n",
      "models:  130 {'model_name': 'slim-sa-ner-tool', 'display_name': 'slim-sa-ner-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'sa-ner.gguf', 'gguf_repo': 'llmware/slim-sa-ner-tool', 'link': 'https://huggingface.co/llmware/slim-sa-ner-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['sentiment, person, organization, place'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-extract', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  131 {'model_name': 'slim-tags-3b', 'display_name': 'llmware/slim-tags-3b', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-tags-3b', 'hf_repo': 'llmware/slim-tags-3b', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'marker_tokens': [], 'marker_token_lookup': {}, 'primary_keys': ['tags'], 'fc_output_values': [], 'function': ['classify']}\n",
      "models:  132 {'model_name': 'slim-tags-3b-tool', 'display_name': 'slim-tags-3b-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-tags-3b.gguf', 'gguf_repo': 'llmware/slim-tags-3b-tool', 'link': 'https://huggingface.co/llmware/slim-tags-3b-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'dict', 'function_call': True, 'primary_keys': ['tags'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-extract', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['classify'], 'snapshot': True}\n",
      "models:  133 {'model_name': 'slim-summary', 'display_name': 'llmware/slim-summary', 'model_family': 'HFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'hf_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': '', 'gguf_repo': '', 'link': 'https://huggingface.co/llmware/slim-summary', 'hf_repo': 'llmware/slim-summary', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'list', 'function_call': True, 'marker_tokens': [], 'marker_token_lookup': {}, 'primary_keys': ['key points (3)'], 'fc_output_values': [], 'function': ['summarize']}\n",
      "models:  134 {'model_name': 'slim-summary-tool', 'display_name': 'slim-summary-tool', 'model_family': 'GGUFGenerativeModel', 'model_category': 'generative_local', 'model_location': 'llmware_repo', 'context_window': 2048, 'instruction_following': False, 'prompt_wrapper': 'human_bot', 'temperature': 0.0, 'sample_default': False, 'trailing_space': '', 'gguf_file': 'slim-summarize.gguf', 'gguf_repo': 'llmware/slim-summary-tool', 'link': 'https://huggingface.co/llmware/slim-summary-tool', 'custom_model_files': [], 'custom_model_repo': '', 'output_type': 'list', 'function_call': True, 'primary_keys': ['key points (3)'], 'fc_output_values': [], 'tokenizer': 'llmware/slim-extract', 'marker_tokens': [], 'marker_token_lookup': {}, 'function': ['summarize'], 'snapshot': True}\n"
     ]
    }
   ],
   "source": [
    "for i, model in enumerate(all_models):\n",
    "    print(\"models: \", i, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ~30 embedding models - including Nomic, Jina, leading sentence transformers, llmware industry-bert models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_models = ModelCatalog().list_embedding_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "print(\"\\nEmbedding Models\")<br>\n",
    "for i, model in enumerate(embedding_models):<br>\n",
    "    print(\"embedding models: \", i, model)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ~92 open source models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "open_source_models = ModelCatalog().list_open_source_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<br>\n",
    "print(\"\\nOpen Source Models\")<br>\n",
    "for i, model in enumerate(open_source_models):<br>\n",
    "    print(\"open source models: \", i, model)<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Inference is Easy - same two lines every time<br>\n",
    "  1.  load_model - use the model_name or display_name, and it will be looked up and instantiated<br>\n",
    "  2.  inference -  all models support an inference method - call it to run a basic inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:warning: this is a function calling model - using .inference may lead to unexpected results.   Recommended to use the .function_call method to ensure correct prompt template packaging.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"slim-tags-3b-tool\"\n",
    "model = ModelCatalog().load_model(model_name)\n",
    "response = model.inference(\" ,    ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Key                                              Value\n",
      "0  llm_response             ...\n",
      "1         usage  {'input': 34, 'output': 100, 'total': 134, 'me...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_name = \"phi-3-gguf\"\n",
    "model = ModelCatalog().load_model(model_name)\n",
    "response = model.inference(\"   ?\")\n",
    "\n",
    "df = pd.DataFrame(list(response.items()), columns=['Key', 'Value'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test inference - phi-3-gguf - response:  {'llm_response': '            .  ,  \"  \"', 'usage': {'input': 34, 'output': 100, 'total': 134, 'metric': 'tokens', 'processing_time': 2.8126730918884277}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\ntest inference - {model_name} - response: \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  Check out other examples in Models, Prompts, SLIM-Agents Embeddings, and Use_Cases<br>\n",
    "  -- configuration in loading model - temperature, sample, max_output<br>\n",
    "  -- add models to the Catalog for easy invocation<br>\n",
    "  -- integrating sources and building RAG workflows in Prompts<br>\n",
    "  -- fact-checking and post-processing<br>\n",
    "  -- using function-calls on small specialized models<br>\n",
    "  -- agent based workflows<br>\n",
    "  -- installing embeddings on a library collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
