{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2bd2f3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f3b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" This example demonstrates creating and using knowledge graphs and document graphs \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf2c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llmware.library import Library\n",
    "from llmware.setup import Setup\n",
    "from llmware.graph import Graph\n",
    "from llmware.configs import LLMWareConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa106f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_use_knowledge_graph (library_name):\n",
    "\n",
    "    #   note: steps 1-3 are repeated in several examples and create a basic library with document sources\n",
    "    #   -- if you have already created a library, then skip to step 4\n",
    "\n",
    "    # step 1 - Create library which is the main 'organizing construct' in llmware\n",
    "    print (\"\\nupdate: Step 1 - Creating library: {}\".format(library_name))\n",
    "\n",
    "    library = Library().create_new_library(library_name)\n",
    "\n",
    "    # step 2 - Pull down the sample files from S3 through the .load_sample_files() command\n",
    "    #   --note: if you need to refresh the sample files, set 'over_write=True'\n",
    "    print (\"update: Step 2 - Downloading Sample Files\")\n",
    "\n",
    "    sample_files_path = Setup().load_sample_files(over_write=False)\n",
    "\n",
    "    #   step 3 - point \".add_files\" method to the folder of documents that was just created\n",
    "    #   this method parses all of the documents, text chunks, and captures in MongoDB\n",
    "\n",
    "    print(\"update: Step 3 - Parsing and Text Indexing Files\")\n",
    "\n",
    "    library.add_files(input_folder_path=os.path.join(sample_files_path, \"UN-Resolutions-500\"))\n",
    "\n",
    "    #\n",
    "    #   ***         KNOWLEDGE GRAPH METHODS START HERE      ***\n",
    "    #\n",
    "    #   step 4 - Build the Knowledge Graph from Library\n",
    "    #\n",
    "\n",
    "    # Build the knowledge graph\n",
    "    print (f\"update: Step 4 - Building knowledge graph for library '{library.library_name}'...\")\n",
    "    library.generate_knowledge_graph()\n",
    "\n",
    "    # Knowledge graph artifacts are stored in the library's /nlp folder\n",
    "    print (f\" > Generated knowledge graph artifacts\\nFrom: {library.nlp_path}:\")\n",
    "    for file_name in os.listdir(library.nlp_path):\n",
    "        print (f\"  - {file_name}\")\n",
    "   \n",
    "    #   step 5 - Load Graph object with my_library\n",
    "    graph = Graph(library)\n",
    "\n",
    "    # Get the overall nlp stats\n",
    "    print (f\"\\n > Knowledge graph - nlp stats\")\n",
    "    library_analytics = graph.get_library_data_stats()\n",
    "\n",
    "    print(\"update: library analytics - \", library_analytics)\n",
    "\n",
    "    # Run a pseudo query against the knowledge graph to find related terms\n",
    "    # These terms could be used to 'enhance' search query and weigh more heavily on related concepts\n",
    "    query_term = 'united nations'\n",
    "    print (f\"\\nKnowledge graph - query for '{query_term}'\")\n",
    "    query_results = graph.kg_query(query_term)\n",
    "    for key, value in query_results.items():\n",
    "        print(f\" - {key}: {value}\")\n",
    "\n",
    "    # Related bigrams\n",
    "    print (f\"\\nKnowledge graph - bigrams for '{query_term}'\")\n",
    "    bigrams = graph.kg_query_related_bigrams(query_term)\n",
    "    print(f\"{bigrams}\")\n",
    "\n",
    "    # Query counts\n",
    "    query_term_2 = \"sustainable social development\"\n",
    "    print (f\"\\n > Knowledge graph - query counts for '{query_term_2}'\")\n",
    "    query_counts = graph.kg_query_counts(query_term_2)\n",
    "    print(f\" - {query_counts}\")\n",
    "\n",
    "    # Export for visualization\n",
    "    print (f\"\\n > Knowledge graph - export for visualization for query '{query_term}'\")\n",
    "    red_nodes, nodes, edges = graph.export_graph_with_query_to_visualize(20, query_term)\n",
    "    print (\"nodes for export - \", red_nodes, nodes, edges)\n",
    "\n",
    "    # Export whole graph for visualization\n",
    "    print (f\"\\n > Knowledge graph - export for visualization for whole graph\")\n",
    "    nodes, edges = graph.export_graph_to_visualize(10)\n",
    "    print(\"nodes for export - \", nodes, edges)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a2aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    LLMWareConfig().set_active_db(\"sqlite\")\n",
    "\n",
    "    build_and_use_knowledge_graph(\"kg_test_99_610\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
