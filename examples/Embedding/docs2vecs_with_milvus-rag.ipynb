{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\n<br>\n", "#                   *** FAST START to create vector embeddings from documents ***<br>\n", "#<br>\n", "#   docs2vecs_with_milvus-contracts - parses, text chunks and embeds legal contracts<br>\n", "#   the sample documents (~80 legal template contracts) can be pulled down from a public S3 repo with the command:<br>\n", "#           sample_files_path = Setup().load_sample_files()<br>\n", "#   note: the example assumes that you have installed Milvus and MongoDB per the separate instructions in the README<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "from llmware.library import Library\n", "from llmware.retrieval import Query\n", "from llmware.setup import Setup\n", "from llmware.status import Status\n", "from llmware.prompts import Prompt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def rag (library_name):\n\n", "    # Step 0 - Configuration - we will use these in Step 4 to install the embeddings\n", "    embedding_model = \"industry-bert-contracts\"\n", "    vector_db = \"milvus\"\n\n", "    # Step 1 - Create library which is the main 'organizing construct' in llmware\n", "    print (\"\\nupdate: Step 1 - Creating library: {}\".format(library_name))\n", "    library = Library().create_new_library(library_name)\n\n", "    # Step 2 - Pull down the sample files from S3 through the .load_sample_files() command\n", "    #   --note: if you need to refresh the sample files, set 'over_write=True'\n", "    print (\"update: Step 2 - Downloading Sample Files\")\n", "    sample_files_path = Setup().load_sample_files(over_write=False)\n", "    contracts_path = os.path.join(sample_files_path, \"Agreements\")\n\n", "    # Step 3 - point \".add_files\" method to the folder of documents that was just created\n", "    #   this method parses all of the documents, text chunks, and captures in MongoDB\n", "    print(\"update: Step 3 - Parsing and Text Indexing Files\")\n", "    library.add_files(input_folder_path=contracts_path)\n\n", "    # Step 4 - Install the embeddings\n", "    print(\"\\nupdate: Step 4 - Generating Embeddings in {} db - with Model- {}\".format(vector_db, embedding_model))\n", "    library.install_new_embedding(embedding_model_name=embedding_model, vector_db=vector_db)\n\n", "    # note: for using llmware as part of a larger application, you can check the real-time status by polling Status()\n", "    #   --both the EmbeddingHandler and Parsers write to Status() at intervals while processing\n", "    update = Status().get_embedding_status(library_name, embedding_model)\n", "    print(\"update: Embeddings Complete - Status() check at end of embedding - \", update)\n", "    print(\"\\nupdate: Loading 1B parameter BLING model for LLM inference\")\n", "    prompter = Prompt().load_model(\"llmware/bling-1b-0.1\")\n", "    query = \"what is the executive's base annual salary\"\n", "    results = Query(library).semantic_query(query, result_count=50, embedding_distance_threshold=1.0)\n", "    for i, res in enumerate(results):\n", "        print(\"update: \", i, res[\"file_source\"], res[\"distance\"], res[\"text\"])\n", "    for i, contract in enumerate(os.listdir(contracts_path)):\n", "        qr = []\n", "        if contract != \".DS_Store\":\n", "            print(\"\\nContract Name: \", i, contract)\n", "            for j, entries in enumerate(results):\n", "                if entries[\"file_source\"] == contract:\n", "                    print(\"Top Retrieval: \", j, entries[\"distance\"], entries[\"text\"])\n", "                    qr.append(entries)\n", "            source = prompter.add_source_query_results(query_results=qr)\n", "            response = prompter.prompt_with_source(query, prompt_name=\"default_with_context\", temperature=0.3)\n", "            for resp in response:\n", "                if \"llm_response\" in resp:\n", "                    print(\"\\nupdate: llm answer - \", resp[\"llm_response\"])\n\n", "            # start fresh for next document\n", "            prompter.clear_source_materials()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}