{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nThis embedding example shows how you can use llmware in combination with OpenAI embedding models to create<br>\n", "a library that you can query semantically.<br>\n", "This example script can be easily extended towards RAG. You can, for exmaple, create a function<br>\n", "that reveices the result from the query as context for a LLM to generate an answer.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import logging"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llmware.library import Library\n", "from llmware.retrieval import Query\n", "from llmware.setup import Setup"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["logging.basicConfig(level = logging.INFO)\n", "logger = logging.getLogger('llmware-pinecone-openai')"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\nChange the values below to your API keys, and the cloud and region you want to use. If you want to use the<br>\n", "bash script, then you have to comment out the following code lines.<br>\n", "See the Pinecone documentation for details on available cloud and region options. During testing, we used<br>\n", "'aws' for cloud and 'us-west-2' for region.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ['USER_MANAGED_PINECONE_API_KEY'] = ''\n", "os.environ['USER_MANAGED_PINECONE_CLOUD'] = ''\n", "os.environ['USER_MANAGED_PINECONE_REGION'] = ''"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ['USER_MANAGED_OPENAI_API_KEY'] = ''"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_up_api_keys(\n", "    pinecone_api_key=os.getenv('USER_MANAGED_PINECONE_API_KEY', None),\n", "    pinecone_cloud=os.getenv('USER_MANAGED_PINECONE_CLOUD', None),\n", "    pinecone_region=os.getenv('USER_MANAGED_PINECONE_REGION', None),\n", "    openai_api_key=os.getenv('USER_MANAGED_OPENAI_API_KEY', None)):\n", "    '''This function sets the API keys for Pinecone and OpenAI, they have to be set!\n", "    '''\n", "    logger.info('Setting up Pinecone and OpenAI API keys')\n", "    if pinecone_api_key in [None, '']:\n", "        raise ValueError(f'You need to set the pinecone API key, got {pinecone_api_key}')\n", "    if pinecone_cloud in [None, '']:\n", "        raise ValueError(f'You need to set the pinecone cloud, got {pinecone_environment}')\n", "    if pinecone_region in [None, '']:\n", "        raise ValueError(f'You need to set the pinecone cloud, got {pinecone_region}')\n", "    if openai_api_key in [None, '']:\n", "        raise ValueError(f'You need to set the OpenAI API key, got {openai_api_key}')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    os.environ.setdefault('USER_MANAGED_PINECONE_API_KEY', pinecone_api_key)\n", "    os.environ.setdefault('USER_MANAGED_PINECONE_CLOUD', pinecone_cloud)\n", "    os.environ.setdefault('USER_MANAGED_PINECONE_REGION', pinecone_region)\n", "    os.environ.setdefault('USER_MANAGED_OPENAI_API_KEY', openai_api_key)\n", "    "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_up_agreements():\n", "    '''This function makes sure that the sample files are loaded, and returns the path the Agreements\n", "    folter. We need the path to the agreements folder for the ``Library`` object.\n", "    If you have your own data, simply exchange this function with another one that returns a path\n", "    to you sample files.\n", "    '''\n", "    logger.info('Setting up Aggreements')\n", "    sample_files_path = Setup().load_sample_files()\n", "    return os.path.join(sample_files_path, \"Agreements\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_up_library(\n", "    input_folder_path,\n", "    library_name='example_pinecone_openai'):\n", "    '''This function creates the library with name ``library_name`` from ``directory``.\n", "    '''\n", "    logger.info(f'Setting up library with name {library_name} from directory {input_folder_path}')\n", "    library = Library().create_new_library(library_name)\n", "    library.add_files(input_folder_path=input_folder_path)\n", "    return library"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def set_up_embeddings(\n", "    library,\n", "    embedding_model='text-embedding-ada-002'):\n", "    '''This function sets up the embeddings in ``library`` with the model ``embedding_model``.\n", "    If you bring your own data and this data contains text and images, than you need to change ``embedding_model``\n", "    to one that can process both simultanously.\n", "    '''\n", "    logger.info(f'Setting up embeddings in library {library.library_name} with model {embedding_model}')\n", "    library.install_new_embedding(embedding_model_name=embedding_model, vector_db=\"pinecone\")\n", "    return library"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def query_library(\n", "    library,\n", "    semantic_query='Salary'):\n", "    '''This function executes the semantic query ``query`` on ``library``.\n", "    If you want to query for something else, simply overwrite ``semantic_query``.\n", "    '''\n", "    query = Query(library)\n", "    query_results = query.semantic_query(query=semantic_query, result_count=10, results_only=True)\n", "    for idx, query_result in enumerate(query_results):\n", "        # each query result is a dictionary with many useful keys\n", "        text = query_result['text']\n", "        file_source = query_result['file_source']\n", "        page_num = query_result['page_num']\n", "        distance = query_result['distance']\n\n", "        # We truncate the text because we want to only show a peak.\n", "        if len(text) > 125:  text = f'{text[0:125]} ...'\n", "        logger.info(f'{idx} query result: {distance} distance '\\\n", "                    f'from file {file_source} and page number {page_num}, '\\\n", "                    f'here is sample text:\\n{text}')\n", "    return query_results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def main():\n", "    '''This function first sets the environment variables for OpenAI and pinecone. Then, it sets up the example data,\n", "    which in this case are the Agreements we provide as part of our sample data. Next, it creates a library with the\n", "    content of the Agreements before it embedds the content. Finally, it performs a sematnic query on the library.\n", "    '''\n", "    set_up_api_keys()\n", "    path_agreements = set_up_agreements()\n", "    library = set_up_library(input_folder_path=path_agreements)\n", "    library = set_up_embeddings(library=library)\n", "    query_library(library=library)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == '__main__':\n", "    main()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}