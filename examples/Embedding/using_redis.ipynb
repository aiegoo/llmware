{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nThis example shows how to use Redis as a vector embedding database with llmware\n<br>\n", "(A) Python Dependencies - "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    As a first step, you should pip install dependencies not included in the llmware package:\n", "        -- pip3 install redis\n", "    \n", "    (B) Installing Redis - \n", "    \n", "    If you need help installing Redis, please see the official redis implementation docs (or many widely available tutorials), e.g.,:\n", "        -- https://redis.io/docs/install/install-redis/\n", "        -- for a fast development install with docker-compose:\n", "             -- please see docker-compose-redis-stack.yaml in the llmware repository\n", "    (C) Configurations - \n", "        -- set os.environ variables to 'automatically' pass in installing embedding\n", "        -- os.environ[\"USER_MANAGED_REDIS_HOST\"] = \"localhost\"\n", "        -- os.environ[\"USER_MANAGED_REDIS_PORT\"] = 6379\n", "        \n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llmware.setup import Setup\n", "from llmware.library import Library\n", "from llmware.retrieval import Query"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_lib (library_name, folder=\"Agreements\"):\n\n", "    # Step 1 - Create library which is the main 'organizing construct' in llmware\n", "    print (\"\\nupdate: Step 1 - Creating library: {}\".format(library_name))\n", "    library = Library().create_new_library(library_name)\n\n", "    # Step 2 - Pull down the sample files from S3 through the .load_sample_files() command\n", "    #   --note: if you need to refresh the sample files, set 'over_write=True'\n", "    print (\"update: Step 2 - Downloading Sample Files\")\n", "    sample_files_path = Setup().load_sample_files(over_write=False)\n\n", "    # Step 3 - point \".add_files\" method to the folder of documents that was just created\n", "    #   this method parses the documents, text chunks, and captures in MongoDB\n", "    print(\"update: Step 3 - Parsing and Text Indexing Files\")\n\n", "    #   options:   Agreements | UN-Resolutions-500\n", "    library.add_files(input_folder_path=os.path.join(sample_files_path, folder))\n", "    return library"]}, {"cell_type": "markdown", "metadata": {}, "source": ["start script"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"update: Step 1- starting here- building library- parsing PDFs into text chunks\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lib = build_lib(\"redis_lib_1114_0\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["optional - check the status of the library card and embedding"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lib_card = lib.get_library_card()\n", "print(\"update: -- before embedding process - check library card - \", lib_card)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"update: Step 2 - starting to install embeddings\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  alt embedding models - \"mini-lm-sbert\" | industry-bert-contracts |  text-embedding-ada-002<br>\n", "  note: if you want to use text-embedding-ada-002, you will need an OpenAI key and enter into os.environ variable<br>\n", "  e.g., os.environ[\"USER_MANAGED_OPENAI_API_KEY\"] = \"<insert your key>\""]}, {"cell_type": "markdown", "metadata": {}, "source": ["  batch sizes from 100-500 usually give good performance and work on most environments"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lib.install_new_embedding(embedding_model_name=\"industry-bert-contracts\",vector_db=\"redis\",batch_size=300)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  optional - check the status of the library card and embedding"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["lib_card = lib.get_library_card()\n", "print(\"update: -- after embedding process - check updated library card - \", lib_card)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  run a query<br>\n", "  note: embedding_model_name is optional, but useful if you create multiple embeddings on the same library<br>\n", "  --see other example scripts for multiple embeddings"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  create query object"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["query_pgv = Query(lib, embedding_model_name=\"industry-bert-contracts\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  run multiple queries using query_pgv"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["my_search_results = query_pgv.semantic_query(\"What is the sale bonus?\", result_count = 24)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["for i, qr in enumerate(my_search_results):\n", "    print(\"update: semantic query results: \", i, qr)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["if you want to delete the embedding  - uncomment the line below<br>\n", "lib.delete_installed_embedding(\"industry-bert-contracts\", \"redis\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  optional - check the embeddings on the library"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}