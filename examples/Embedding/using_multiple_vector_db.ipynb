{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nThis example shows how to use a single library and attach 'mix-and-match' multiple vector databases with<br>\n", "    potentially multiple different embedding models<br>\n", "    Use case:   evaluate and compare multiple combinations of vector databases and embedding models using the<br>\n", "                same core text library - without having to recreate - enables fast experimentation without lock-in.<br>\n", "    Note:<br>\n", "        -- the example belows requires installation of several vector db- Milvus, PGVector, Redis and FAISS<br>\n", "        -- docker-compose scripts for rapid install for Milvus, PGVector and Redis in the llmware repository<br>\n", "        -- no install required for FAISS<br>\n", "        -- please also see the install instructions in the Examples/Embeddings for more install pre-reqs, e.g.,:<br>\n", "                --Milvus: pip install pymilvus<br>\n", "                --Redis-Stack-Server: pip install redis<br>\n", "                --Postgres:  pip install psycopg-binary psycopg pgvector<br>\n", "  \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llmware.setup import Setup\n", "from llmware.library import Library\n", "from llmware.retrieval import Query\n", "from llmware.models import ModelCatalog"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ[\"USER_MANAGED_OPENAI_API_KEY\"] = \"<INSERT YOUR OPEN AI KEY HERE>\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Avoid a HuggingFace tokenizer warning"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  Note:  this will build a small library that will be used in the embedding examples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_lib (library_name, folder=\"Agreements\"):\n\n", "    # Step 1 - Create library which is the main 'organizing construct' in llmware\n", "    print (\"\\nupdate: creating library: {}\".format(library_name))\n", "    library = Library().create_new_library(library_name)\n\n", "    # Step 2 - Pull down the sample files from S3 through the .load_sample_files() command\n", "    #   --note: if you need to refresh the sample files, set 'over_write=True'\n", "    print (\"update: downloading sample files\")\n", "    sample_files_path = Setup().load_sample_files(over_write=False)\n\n", "    # Step 3 - point \".add_files\" method to the folder of documents that was just created\n", "    #   this method parses the documents, text chunks, and captures in MongoDB\n", "    print(\"update: parsing and text indexing Files\")\n\n", "    #   options:   Agreements | UN-Resolutions-500\n", "    library.add_files(input_folder_path=os.path.join(sample_files_path, folder))\n", "    return library"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def multiple_embeddings_and_multiple_vector_dbs(document_folder=None,sample_query=\"\", base_library_name=\"\"):\n", "    print(\"\\nupdate: Step 1- starting here- building library- parsing PDFs into text chunks\")\n", "    lib = build_lib(base_library_name, folder=document_folder)\n\n", "    # optional - check the status of the library card and embedding\n", "    lib_card = lib.get_library_card()\n", "    print(\"update: library card - \", lib_card)\n", "    print(\"\\nupdate: Step 2 - starting to install embeddings\")\n\n", "    #   mix-and-match with different embedding models and vector db on same library content\n\n", "    #   We will create 6 different embeddings across 4 different vector databases - using the same library\n", "    #   note: you can run many different models on the same db, or the same model across multiple dbs\n", "    print(\"\\nupdate: Embedding #1 - industry-bert-contracts - on PG_Vector\")\n", "    lib.install_new_embedding(embedding_model_name=\"industry-bert-contracts\",vector_db=\"pg_vector\",batch_size=300)\n", "    print(\"\\nupdate: Embedding #2 - mini-lm-sbert - Milvus\")\n", "    lib.install_new_embedding(embedding_model_name=\"mini-lm-sbert\", vector_db=\"milvus\", batch_size=200)\n", "    print(\"\\nupdate: Embedding #3 - mini-lm-sbert - on PG_Vector\")\n", "    lib.install_new_embedding(embedding_model_name=\"mini-lm-sbert\", vector_db=\"pg_vector\", batch_size=100)\n", "    print(\"\\nupdate: Embedding #4 - text-embedding-ada-002 - FAISS\")\n", "    lib.install_new_embedding(embedding_model_name=\"text-embedding-ada-002\", vector_db=\"faiss\", batch_size=500)\n", "    print(\"\\nupdate: Embedding #5 - industry-bert-sec - REDIS\")\n", "    lib.install_new_embedding(embedding_model_name=\"industry-bert-sec\", vector_db=\"redis\", batch_size=350)\n\n", "    # for the last embedding, we will register a pretrained sentence transformer model to use\n", "    #   -- see \"using_sentence_transformer.py\" for more details\n", "    ModelCatalog().register_sentence_transformer_model(model_name= \"all-MiniLM-L6-v2\",\n", "                                                       embedding_dims=384, context_window=256)\n\n", "    # use directly now as an embedding model\n", "    print(\"\\nupdate: Embedding #6 - all-MiniLM-L6-v2 - REDIS\")\n", "    lib.install_new_embedding(embedding_model_name=\"all-MiniLM-L6-v2\",vector_db=\"redis\",batch_size=300)\n\n", "    #   optional - check the embeddings on the library\n", "    print(\"\\nupdate: Embedding record of the Library\")\n", "    emb_record = lib.get_embedding_status()\n", "    for j, entries in enumerate(emb_record):\n", "        print(\"update: embeddings on library: \", j, entries)\n\n", "    #   Using the Embeddings to Execute Queries\n", "    #\n", "    #   create query object:\n", "    #   1.  if no embedding_model or vector_db passed in constructor, then selects the LAST embedding record, which\n", "    #        is the most recent embedding on the library, and uses that combination of model + vector db\n", "    #\n", "    #   2.  if embedding_model_name only passed, then looks up the first instance of that embedding model\n", "    #       in the embedding record, and will use the associated vector db\n", "    #\n", "    #   3.  if both embedding_model_name and vector_db passed in constructor, then looks up that combo in\n", "    #        embedding record\n", "    q = Query(lib, embedding_model_name=\"mini-lm-sbert\", vector_db=\"pg_vector\")\n\n", "    #   to execute query against any of the query objects:\n", "    #   --just showing one example\n", "    my_search_results = q.semantic_query(sample_query, result_count=15)\n", "    print(\"\\n\\nupdate: Sample Query using Embeddings\")\n", "    for i, qr in enumerate(my_search_results):\n", "        print(\"update: semantic query results: \", i, qr)\n\n", "    # if you want to delete any of the embeddings  - uncomment the line below\n", "    # lib.delete_installed_embedding(\"industry-bert-contracts\", \"pg_vector\")\n", "    return 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    multiple_embeddings_and_multiple_vector_dbs(document_folder=\"Agreements\",\n", "                                                sample_query=\"what is the base salary?\",\n", "                                                base_library_name=\"multi-embedding-multi-db-test-1\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}