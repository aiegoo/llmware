{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["\nThis example shows how to easily create multiple embeddings over the same library with llmware<br>\n", "    This recipe can be especially useful when trying to compare the effectiveness of a particular<br>\n", "    embedding model for a specific domain or library corpus and to run other comparative experiments<br>\n", "    without being 'locked-in' to a particular model.<br>\n", "    Note: the example uses four different embedding models:<br>\n", "        1.  mini-lm-sbert - a favorite small, fast Sentence Transformer included in the llmware model catalog by default<br>\n", "        2.  text-embedding-ada-002 - the popular OpenAI embedding model<br>\n", "        3.  industry-bert-sec - an industry fine-tuned embedding model, in the llmware model catalog<br>\n", "        4.  all-mpnet-base-v2 - one of the most popular Sentence Transformers (which we will register and add to the<br>\n", "            model catalog on the fly<br>\n", "        To use OpenAI Ada will require an Open API key - if you do not have one, feel free to comment out or<br>\n", "        select a different model.  Any Sentence Transformer or Huggingface embedding model can be used.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from llmware.setup import Setup\n", "from llmware.library import Library\n", "from llmware.retrieval import Query\n", "from llmware.models import ModelCatalog"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ[\"USER_MANAGED_OPENAI_API_KEY\"] = \"<INSERT YOUR OPEN API KEY HERE>\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"  # Avoid a HuggingFace tokenizer warning"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  Note:  this will build a small library that will be used in the embedding examples"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def build_lib (library_name, folder=\"Agreements\"):\n\n", "    # Step 1 - Create library which is the main 'organizing construct' in llmware\n", "    print (\"\\nupdate: creating library: {}\".format(library_name))\n", "    library = Library().create_new_library(library_name)\n\n", "    # Step 2 - Pull down the sample files from S3 through the .load_sample_files() command\n", "    #   --note: if you need to refresh the sample files, set 'over_write=True'\n", "    print (\"update: downloading sample files\")\n", "    sample_files_path = Setup().load_sample_files(over_write=False)\n\n", "    # Step 3 - point \".add_files\" method to the folder of documents that was just created\n", "    #   this method parses the documents, text chunks, and captures in MongoDB\n", "    print(\"update: parsing and text indexing files\")\n\n", "    #   options:   Agreements | UN-Resolutions-500\n", "    library.add_files(input_folder_path=os.path.join(sample_files_path, folder))\n", "    return library"]}, {"cell_type": "markdown", "metadata": {}, "source": ["  use multiple embedding models on the same library and the same vector db"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def multiple_embeddings_same_db_same_lib(document_folder=None,sample_query=None,vector_db=None, base_library_name=None):\n", "    print(\"\\nupdate: Step 1- starting here- building library- parsing PDFs into text chunks\")\n", "    lib = build_lib(base_library_name, folder=document_folder)\n\n", "    # optional - check the status of the library card and embedding\n", "    lib_card = lib.get_library_card()\n", "    print(\"update: library card - \", lib_card)\n", "    print(\"\\nupdate: Step 2 - starting to install embeddings\")\n\n", "    #   alt embedding models - \"mini-lm-sbert\" | industry-bert-contracts |  text-embedding-ada-002\n", "    #   note: if you want to use text-embedding-ada-002, you will need an OpenAI key and enter into os.environ variable\n", "    #   e.g., os.environ[\"USER_MANAGED_OPENAI_API_KEY\"] = \"<insert your key>\"\n\n", "    #   Note: batch size can be configured based on memory of machine and optimized for performance\n", "    #   -- generally, between 100-500 is a safe range to optimize performance/memory\n", "    print(f\"\\nupdate: Embedding #1 - mini-lm-sbert - {vector_db}\")\n", "    lib.install_new_embedding(embedding_model_name=\"mini-lm-sbert\", vector_db=vector_db, batch_size=200)\n", "    print(f\"\\nupdate: Embedding #2 - text-embedding-ada-002 - {vector_db}\")\n", "    lib.install_new_embedding(embedding_model_name=\"text-embedding-ada-002\", vector_db=vector_db, batch_size=500)\n", "    print(f\"\\nupdate: Embedding #3 - industry-bert-sec - {vector_db}\")\n", "    lib.install_new_embedding(embedding_model_name=\"industry-bert-sec\", vector_db=vector_db, batch_size=100)\n\n", "    # for the last embedding, we will register a popular open source sentence transformer model to use\n", "    #   -- see \"using_sentence_transformer.py\" for more details\n", "    ModelCatalog().register_sentence_transformer_model(model_name=\"all-mpnet-base-v2\",\n", "                                                       embedding_dims=768, context_window=384)\n\n", "    # use directly now as an embedding model\n", "    print(f\"\\nupdate: Embedding #4 - all-mpnet-base-v2 - {vector_db}\")\n", "    lib.install_new_embedding(embedding_model_name=\"all-mpnet-base-v2\",vector_db=vector_db,batch_size=300)\n\n", "    #   optional - check the embeddings on the library\n", "    print(\"\\nupdate: Embedding record of the Library\")\n", "    emb_record = lib.get_embedding_status()\n", "    for j, entries in enumerate(emb_record):\n", "        print(\"update: embeddings on library: \", j, entries)\n\n", "    #   Using the Embeddings to Execute Queries\n", "    #\n", "    #   create query object:\n", "    #   1.  if no embedding_model or vector_db passed in constructor, then selects the LAST embedding record, which\n", "    #        is the most recent embedding on the library, and uses that combination of model + vector db\n", "    #\n", "    #   2.  if embedding_model_name only passed, then looks up the first instance of that embedding model\n", "    #       in the embedding record, and will use the associated vector db\n", "    #\n", "    #   3.  if both embedding_model_name and vector_db passed in constructor, then looks up that combo in\n", "    #        embedding record.\n", "    query1 = Query(lib, embedding_model_name=\"mini-lm-sbert\")\n", "    query2 = Query(lib, embedding_model_name=\"text-embedding-ada-002\")\n\n", "    #   to execute query against any of the query objects\n", "    minilm_results = query1.semantic_query(sample_query, result_count=12)\n", "    ada_results = query2.semantic_query(sample_query, result_count=12)\n", "    print(\"\\n\\nupdate: Sample Query using Embeddings\")\n", "    print(\"\\nupdate: Embedding Model # 1 - MiniLM SBERT Results\")\n", "    for i, qr1 in enumerate(minilm_results):\n", "        print(\"update: minilm semantic query results: \", i, qr1[\"distance\"], qr1)\n", "    print(\"\\nupdate: Embedding Model # 2- Ada Results\")\n", "    for j, qr2 in enumerate(ada_results):\n", "        print(\"update: ada semantic query results: \", j, qr2[\"distance\"], qr2)\n", "    return 0"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n\n", "    #   document folder options:  Agreements | UN-Resolutions-500\n", "    #   note: Agreements = ~15 contracts = ~1272 embeddings - takes ~5 minutes to run (without GPU)\n", "    #   note: UN-Resolutions-500 = 500 documents = ~12500 embeddings - takes ~15-20 minutes to run (without GPU)\n", "    #       -- good sample query for UN-Resolutions, e.g. \"what are key initiatives to promote sustainability?\"\n", "    #\n", "    #   try substituting different vector-db, e.g, \"pg_vector\" | \"redis\" | \"faiss\"\n", "    multiple_embeddings_same_db_same_lib(document_folder=\"Agreements\",\n", "                                         sample_query=\"what is the sale bonus?\",\n", "                                         vector_db=\"milvus\",\n", "                                         base_library_name=\"multi_embeddings_test_lib_0\")"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}